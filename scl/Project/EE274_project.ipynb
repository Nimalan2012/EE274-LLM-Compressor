{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngflqp2FaJDJ"
      },
      "source": [
        "Clone LLM compressor repository and move to project directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t-mgiwbwrVoy",
        "outputId": "660ed794-7f3a-43f4-8d40-b0f1142185d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EE274-LLM-Compressor'...\n",
            "remote: Enumerating objects: 1541, done.\u001b[K\n",
            "remote: Counting objects: 100% (1541/1541), done.\u001b[K\n",
            "remote: Compressing objects: 100% (540/540), done.\u001b[K\n",
            "remote: Total 1541 (delta 1016), reused 1491 (delta 978), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1541/1541), 486.25 KiB | 1.04 MiB/s, done.\n",
            "Resolving deltas: 100% (1016/1016), done.\n",
            "/content/EE274-LLM-Compressor/scl/Project\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Nimalan2012/EE274-LLM-Compressor.git\n",
        "%cd EE274-LLM-Compressor/scl/Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2yBJl0irVdV"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c7efb2e9",
        "outputId": "4ade948d-7976-41e3-e3e6-412d132b847a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitarray\n",
            "  Downloading bitarray-3.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
            "Downloading bitarray-3.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (340 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/340.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.3/340.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitarray\n",
            "Successfully installed bitarray-3.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install bitarray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdujKLwraexN"
      },
      "source": [
        "Run a sample text to compress and decompress. Uses TinyLlama model as default.\n",
        "\n",
        "\"The weather today is sunny and pleasant. I expect light winds and warm sunshine.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o0QJzCl9WDGf",
        "outputId": "c1fd0f22-dad3-496b-b24a-3246845670ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-12 05:37:53.081654: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-12 05:37:53.099496: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765517873.120962    1374 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765517873.127393    1374 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765517873.143952    1374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765517873.143988    1374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765517873.143991    1374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765517873.143994    1374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-12 05:37:53.148716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 1.29kB [00:00, 5.90MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:01<00:00, 403kB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 4.08MB/s]\n",
            "tokenizer.json: 1.84MB [00:00, 29.1MB/s]\n",
            "config.json: 100% 608/608 [00:00<00:00, 5.94MB/s]\n",
            "model.safetensors: 100% 2.20G/2.20G [00:05<00:00, 418MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 696kB/s]\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Processing 21 tokens...\n",
            "Compression time: 2.080 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    80 bytes\n",
            "   Compressed Size:  16.75 bytes\n",
            "   Compression Ratio: 4.776x\n",
            "   Bits Per Byte:    1.675 bpb\n",
            "   Speed:            38.46 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.7927 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  6.3810 bits/token\n",
            "   Overhead:         1.5883 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 1.036 sec\n",
            "\n",
            "Recovered text snippet: The weather today is sunny and pleasant. I expect light winds and warm sunshine.\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w48_uG1Oa0MM"
      },
      "source": [
        ":Test different models on truncated alice29 dataset (10kB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "47b6cOjxgdID",
        "outputId": "9e48dcc3-462e-486a-e7c5-26c0648ad947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 04:56:56.313140: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 04:56:56.330665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764737816.352886    1296 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764737816.359491    1296 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764737816.376248    1296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764737816.376286    1296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764737816.376289    1296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764737816.376292    1296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 04:56:56.381297: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 1.29kB [00:00, 8.53MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:01<00:00, 363kB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 6.18MB/s]\n",
            "tokenizer.json: 1.84MB [00:00, 130MB/s]\n",
            "config.json: 100% 608/608 [00:00<00:00, 5.31MB/s]\n",
            "model.safetensors: 100% 2.20G/2.20G [00:06<00:00, 361MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 1.45MB/s]\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 2759 tokens...\n",
            "Compression time: 120.730 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1000.75 bytes\n",
            "   Compression Ratio: 9.793x\n",
            "   Bits Per Byte:    0.817 bpb\n",
            "   Speed:            81.17 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  2.8897 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  2.9018 bits/token\n",
            "   Overhead:         0.0121 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 136.480 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model tinyllama --infile alice_10k.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "72xs1lxyI5U-",
        "outputId": "ba22a259-24d1-41e4-f399-f8b26866377e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 05:01:45.847220: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 05:01:45.865517: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764738105.887677    2657 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764738105.894369    2657 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764738105.911434    2657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764738105.911473    2657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764738105.911476    2657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764738105.911478    2657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 05:01:45.916748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 100% 156/156 [00:00<00:00, 1.33MB/s]\n",
            "vocab.json: 1.08MB [00:00, 131MB/s]\n",
            "merges.txt: 457kB [00:00, 114MB/s]\n",
            "tokenizer.json: 2.11MB [00:00, 153MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 1.07MB/s]\n",
            "config.json: 100% 879/879 [00:00<00:00, 9.38MB/s]\n",
            "model.safetensors.index.json: 38.2kB [00:00, 127MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/528M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 8.13k/4.96G [00:01<335:45:25, 4.10kB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 35.3k/528M [00:02<8:41:01, 16.9kB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 204M/528M [00:02<00:02, 129MB/s]    \u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 338M/528M [00:02<00:00, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 461M/528M [00:02<00:00, 317MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 528M/528M [00:03<00:00, 166MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 727M/4.96G [00:03<00:11, 378MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 879M/4.96G [00:03<00:10, 376MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 961M/4.96G [00:03<00:11, 362MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.96G [00:04<00:09, 394MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.96G [00:04<00:09, 420MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.22G/4.96G [00:04<00:09, 408MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.96G [00:06<00:33, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.96G [00:06<00:17, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.96G [00:06<00:13, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.96G [00:07<00:16, 205MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.41G/4.96G [00:07<00:03, 716MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.96G [00:08<00:03, 642MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.96G [00:08<00:03, 560MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.96G [00:10<00:08, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.96G [00:10<00:07, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.96G [00:12<00:09, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.20G/4.96G [00:12<00:08, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.25G/4.96G [00:13<00:11, 150MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.96G [00:13<00:10, 161MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.96G [00:13<00:08, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.96G [00:14<00:08, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.96G [00:14<00:06, 223MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.96G [00:14<00:05, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.96G [00:14<00:06, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.96G [00:14<00:06, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.96G [00:15<00:06, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.78G/4.96G [00:15<00:05, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.96G [00:15<00:06, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.96G [00:16<00:07, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.96G [00:16<00:05, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.96G [00:16<00:04, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.96G [00:16<00:02, 328MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.96G [00:17<00:03, 216MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.96G [00:17<00:03, 259MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.96G [00:17<00:02, 256MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.96G [00:17<00:02, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.96G [00:17<00:01, 373MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.96G [00:18<00:01, 271MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.96G [00:18<00:01, 302MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.96G [00:18<00:01, 294MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.96G [00:18<00:00, 323MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.96G [00:19<00:01, 161MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.96G [00:19<00:00, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.96G [00:20<00:00, 160MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.96G [00:21<00:00, 227MB/s] \n",
            "Fetching 2 files: 100% 2/2 [00:22<00:00, 11.21s/it]\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.91it/s]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 1.30MB/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Processing 2567 tokens...\n",
            "Compression time: 223.146 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  939.12 bytes\n",
            "   Compression Ratio: 10.435x\n",
            "   Bits Per Byte:    0.767 bpb\n",
            "   Speed:            43.92 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  2.9206 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  2.9268 bits/token\n",
            "   Overhead:         0.0061 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.85it/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 249.584 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba1.4b --infile alice_10k.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Jpn6NecMxk"
      },
      "source": [
        "Test scale of model with mamba architecture of 130m parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6aMTHm5hJHnr",
        "outputId": "6e5e5b98-9ff8-417e-ebf6-19433cbc7091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 05:10:24.032388: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 05:10:24.049872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764738624.071387    4927 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764738624.077882    4927 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764738624.094107    4927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764738624.094140    4927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764738624.094143    4927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764738624.094145    4927 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 05:10:24.099031: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "config.json: 100% 895/895 [00:00<00:00, 8.14MB/s]\n",
            "model.safetensors: 100% 517M/517M [00:04<00:00, 121MB/s]\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 1.43MB/s]\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 2567 tokens...\n",
            "Compression time: 153.600 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1324.62 bytes\n",
            "   Compression Ratio: 7.398x\n",
            "   Bits Per Byte:    1.081 bpb\n",
            "   Speed:            63.80 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.1151 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.1282 bits/token\n",
            "   Overhead:         0.0130 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 176.238 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile alice_10k.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOBOo2gaqKoG"
      },
      "source": [
        "Compressing the full alice29 dataset with different models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsVjUiWTEUX4",
        "outputId": "59f19d79-1621-433a-b812-09b9a5180558",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-05 02:04:05.053402: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 02:04:05.071126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764900245.092477    6081 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764900245.099000    6081 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764900245.115325    6081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764900245.115357    6081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764900245.115361    6081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764900245.115363    6081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 02:04:05.120254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice29.txt ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (43990 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 43990 tokens...\n",
            "Compression time: 1910.610 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    148481 bytes\n",
            "   Compressed Size:  16716.62 bytes\n",
            "   Compression Ratio: 8.882x\n",
            "   Bits Per Byte:    0.901 bpb\n",
            "   Speed:            77.71 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.0393 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.0401 bits/token\n",
            "   Overhead:         0.0008 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 2169.378 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model tinyllama --infile alice29.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mPv0uWmDjm4B",
        "outputId": "fe4f72ad-1fbb-4532-aee8-f36ede686dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-05 07:44:37.157298: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 07:44:37.174637: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764920677.195751    1620 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764920677.202154    1620 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764920677.218293    1620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764920677.218320    1620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764920677.218323    1620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764920677.218327    1620 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 07:44:37.223134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice29.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 100% 156/156 [00:00<00:00, 1.37MB/s]\n",
            "vocab.json: 1.08MB [00:00, 130MB/s]\n",
            "merges.txt: 457kB [00:00, 90.4MB/s]\n",
            "tokenizer.json: 2.11MB [00:00, 176MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 699kB/s]\n",
            "config.json: 100% 895/895 [00:00<00:00, 7.99MB/s]\n",
            "model.safetensors: 100% 517M/517M [00:04<00:00, 124MB/s]\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 1.54MB/s]\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 40383 tokens...\n",
            "Compression time: 2358.363 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    148481 bytes\n",
            "   Compressed Size:  20037.62 bytes\n",
            "   Compression Ratio: 7.410x\n",
            "   Bits Per Byte:    1.080 bpb\n",
            "   Speed:            62.96 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.9692 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.9695 bits/token\n",
            "   Overhead:         0.0003 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 2782.760 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile alice29.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dhFX5rbkjrqz",
        "outputId": "73de4edf-4f04-46d7-878c-ddfd25974482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-05 17:27:25.188232: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 17:27:25.205810: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764955645.227961     537 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764955645.234558     537 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764955645.251257     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764955645.251292     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764955645.251295     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764955645.251298     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 17:27:25.256213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice29.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 100% 156/156 [00:00<00:00, 991kB/s]\n",
            "vocab.json: 1.08MB [00:00, 46.3MB/s]\n",
            "merges.txt: 457kB [00:00, 101MB/s]\n",
            "tokenizer.json: 2.11MB [00:00, 154MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 449kB/s]\n",
            "config.json: 100% 879/879 [00:00<00:00, 7.71MB/s]\n",
            "model.safetensors.index.json: 38.2kB [00:00, 92.7MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/528M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 69.2k/528M [00:01<2:28:45, 59.2kB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 9.33M/528M [00:01<00:51, 9.99MB/s]  \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 2.09M/4.96G [00:01<55:25, 1.49MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   8% 40.8M/528M [00:01<00:10, 45.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 7.39M/4.96G [00:01<13:13, 6.24MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 82.8M/528M [00:01<00:04, 91.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 35.2M/4.96G [00:01<02:20, 35.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  28% 151M/528M [00:01<00:02, 181MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 217M/528M [00:01<00:01, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 345M/528M [00:02<00:00, 401MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 84.2M/4.96G [00:02<01:30, 54.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 428M/528M [00:02<00:00, 346MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 511M/4.96G [00:02<00:09, 457MB/s]  \u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 670M/4.96G [00:02<00:08, 496MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 790M/4.96G [00:04<00:25, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 977M/4.96G [00:05<00:16, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.96G [00:05<00:12, 298MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 528M/528M [00:05<00:00, 102MB/s] \n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.96G [00:05<00:11, 339MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.96G [00:05<00:07, 456MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.96G [00:05<00:07, 490MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.61G/4.96G [00:05<00:07, 449MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.96G [00:06<00:07, 466MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.96G [00:06<00:06, 520MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.96G [00:06<00:09, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.96G [00:09<00:11, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.96G [00:09<00:09, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.96G [00:09<00:06, 371MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.80G/4.96G [00:09<00:04, 487MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.96G [00:09<00:03, 541MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.96G [00:09<00:03, 566MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.96G [00:09<00:02, 617MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.30G/4.96G [00:09<00:02, 698MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.96G [00:10<00:02, 733MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.96G [00:10<00:02, 646MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.61G/4.96G [00:10<00:02, 557MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.96G [00:10<00:02, 494MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.80G/4.96G [00:12<00:07, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.85G/4.96G [00:13<00:08, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.96G [00:13<00:04, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.96G [00:13<00:02, 294MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.96G [00:13<00:01, 470MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.96G [00:13<00:00, 568MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.96G [00:13<00:00, 622MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/4.96G [00:13<00:00, 676MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.96G [00:14<00:00, 351MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:14<00:00,  7.19s/it]\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.08it/s]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 627kB/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Processing 40383 tokens...\n",
            "Compression time: 3590.030 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    148481 bytes\n",
            "   Compressed Size:  15161.62 bytes\n",
            "   Compression Ratio: 9.793x\n",
            "   Bits Per Byte:    0.817 bpb\n",
            "   Speed:            41.36 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.0136 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.0036 bits/token\n",
            "   Overhead:         -0.0100 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  4.17it/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 4032.563 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba1.4b --infile alice29.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV8Sb9eslSfa"
      },
      "source": [
        "Testing on news dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uzfN14d3l8Y8",
        "outputId": "a0ab6f7e-d8d0-4597-ff62-7a1310e15708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 05:31:12.578068: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 05:31:12.596390: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764739872.618941   10664 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764739872.625667   10664 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764739872.642696   10664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764739872.642730   10664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764739872.642734   10664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764739872.642739   10664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 05:31:12.647767: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: news_transcript.txt ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10661 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 10661 tokens...\n",
            "Compression time: 474.149 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    39706 bytes\n",
            "   Compressed Size:  4392.38 bytes\n",
            "   Compression Ratio: 9.040x\n",
            "   Bits Per Byte:    0.885 bpb\n",
            "   Speed:            83.74 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.2929 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.2960 bits/token\n",
            "   Overhead:         0.0031 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 532.023 sec\n",
            "\n",
            "Recovered text snippet: Four Dead, 10 Hurt After Shooting At Family Gathering In California; Major Winter Storm Impacts Post-Thanksgiving Travel For Millions; U.S. And Ukraine To Resume Peace Talks; Rubio To Skip Meeting Of \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model tinyllama --infile news_transcript.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lV716XQzl5gj",
        "outputId": "5281e8ea-76e8-4f97-ac9d-935849c9fe89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 05:56:31.129305: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 05:56:31.146707: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764741391.167918   17044 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764741391.174358   17044 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764741391.190752   17044 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764741391.190781   17044 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764741391.190784   17044 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764741391.190788   17044 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 05:56:31.195697: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: news_transcript.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 9572 tokens...\n",
            "Compression time: 571.757 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    39706 bytes\n",
            "   Compressed Size:  5110.88 bytes\n",
            "   Compression Ratio: 7.769x\n",
            "   Bits Per Byte:    1.030 bpb\n",
            "   Speed:            69.45 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.2691 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.2715 bits/token\n",
            "   Overhead:         0.0024 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 674.835 sec\n",
            "\n",
            "Recovered text snippet: Four Dead, 10 Hurt After Shooting At Family Gathering In California; Major Winter Storm Impacts Post-Thanksgiving Travel For Millions; U.S. And Ukraine To Resume Peace Talks; Rubio To Skip Meeting Of \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile news_transcript.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wQrPIB6tlyFV",
        "outputId": "fa9e8875-2202-419d-9a40-9c04c720ae6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 06:19:09.405264: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 06:19:09.423068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764742749.444525   22664 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764742749.451173   22664 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764742749.467718   22664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764742749.467746   22664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764742749.467749   22664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764742749.467752   22664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 06:19:09.472727: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: news_transcript.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  4.01it/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Processing 9572 tokens...\n",
            "Compression time: 832.221 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    39706 bytes\n",
            "   Compressed Size:  4350.38 bytes\n",
            "   Compression Ratio: 9.127x\n",
            "   Bits Per Byte:    0.877 bpb\n",
            "   Speed:            47.71 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.6392 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.6359 bits/token\n",
            "   Overhead:         -0.0033 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  4.10it/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 931.790 sec\n",
            "\n",
            "Recovered text snippet: Four Dead, 10 Hurt After Shooting At Family Gathering In California; Major Winter Storm Impacts Post-Thanksgiving Travel For Millions; U.S. And Ukraine To Resume Peace Talks; Rubio To Skip Meeting Of \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba1.4b --infile news_transcript.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXqke3tocygN"
      },
      "source": [
        "Test context window impact with truncated alice29 (10KB) file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RtaNIuHvcxs4",
        "outputId": "994bc989-7b8c-427c-9e94-8e671eb42c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 05:17:02.891932: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 05:17:02.909113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764739022.930892    6789 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764739022.937447    6789 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764739022.953496    6789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764739022.953528    6789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764739022.953531    6789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764739022.953535    6789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 05:17:02.958396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 2759 tokens...\n",
            "Compression time: 122.686 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1264.50 bytes\n",
            "   Compression Ratio: 7.750x\n",
            "   Bits Per Byte:    1.032 bpb\n",
            "   Speed:            79.88 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.6546 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.6665 bits/token\n",
            "   Overhead:         0.0120 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 136.534 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model tinyllama --infile alice_10k.txt --context-size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tgcjEaPUdHfK",
        "outputId": "e4bc41f0-428c-4ce7-f927-7b8465949a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 06:48:52.836157: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 06:48:52.853872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764744532.875610   30101 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764744532.882106   30101 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764744532.898637   30101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764744532.898671   30101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764744532.898674   30101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764744532.898677   30101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 06:48:52.903617: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 2759 tokens...\n",
            "Compression time: 121.880 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  955.75 bytes\n",
            "   Compression Ratio: 10.254x\n",
            "   Bits Per Byte:    0.780 bpb\n",
            "   Speed:            80.41 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  2.7594 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  2.7713 bits/token\n",
            "   Overhead:         0.0119 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 136.751 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model tinyllama --infile alice_10k.txt --context-size 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nNo1PQb-HKUr",
        "outputId": "cf6d022f-e954-4e17-acec-fc4bb8ad3fa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-05 01:58:31.128667: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 01:58:31.146787: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764899911.167701    4564 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764899911.174088    4564 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764899911.190573    4564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899911.190600    4564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899911.190603    4564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899911.190605    4564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 01:58:31.195464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 1.29kB [00:00, 5.88MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 668kB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 5.01MB/s]\n",
            "tokenizer.json: 1.84MB [00:00, 58.6MB/s]\n",
            "config.json: 100% 608/608 [00:00<00:00, 5.46MB/s]\n",
            "model.safetensors: 100% 2.20G/2.20G [00:06<00:00, 344MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 742kB/s]\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 2759 tokens...\n",
            "Compression time: 116.861 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  924.88 bytes\n",
            "   Compression Ratio: 10.596x\n",
            "   Bits Per Byte:    0.755 bpb\n",
            "   Speed:            83.86 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  2.6697 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  2.6818 bits/token\n",
            "   Overhead:         0.0121 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 132.075 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model tinyllama --infile alice_10k.txt --context-size 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E673X3tG4u1e",
        "outputId": "84caa0de-3067-48b1-ae05-2b2c5d484a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 06:53:29.959111: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 06:53:29.977318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764744809.998660   31283 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764744810.005186   31283 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764744810.021698   31283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764744810.021738   31283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764744810.021741   31283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764744810.021744   31283 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 06:53:30.026643: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 2759 tokens...\n",
            "Compression time: 124.236 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1679.50 bytes\n",
            "   Compression Ratio: 5.835x\n",
            "   Bits Per Byte:    1.371 bpb\n",
            "   Speed:            78.88 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.8595 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.8699 bits/token\n",
            "   Overhead:         0.0104 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 138.704 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model tinyllama --infile alice_10k.txt --context-size 3000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RRjEywGjdHXU",
        "outputId": "eee143ec-6840-41e2-89c5-16d904d134f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 06:58:11.466450: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 06:58:11.483912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764745091.504858   32483 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764745091.511213   32483 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764745091.527267   32483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745091.527299   32483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745091.527301   32483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745091.527304   32483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 06:58:11.532004: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 2567 tokens...\n",
            "Compression time: 153.055 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1545.88 bytes\n",
            "   Compression Ratio: 6.339x\n",
            "   Bits Per Byte:    1.262 bpb\n",
            "   Speed:            64.03 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.8055 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.8177 bits/token\n",
            "   Overhead:         0.0122 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 176.455 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile alice_10k.txt --context-size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ye9qNdhfGzCQ",
        "outputId": "795d97cf-5c2e-4533-b01a-d9aa386fc971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-05 01:47:09.226822: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 01:47:09.243839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764899229.264779    1512 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764899229.271201    1512 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764899229.287660    1512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899229.287687    1512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899229.287690    1512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899229.287693    1512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 01:47:09.292445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 100% 156/156 [00:00<00:00, 1.47MB/s]\n",
            "vocab.json: 1.08MB [00:00, 50.9MB/s]\n",
            "merges.txt: 457kB [00:00, 136MB/s]\n",
            "tokenizer.json: 2.11MB [00:00, 195MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 868kB/s]\n",
            "config.json: 100% 895/895 [00:00<00:00, 9.22MB/s]\n",
            "model.safetensors: 100% 517M/517M [00:02<00:00, 178MB/s]\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 1.42MB/s]\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 2567 tokens...\n",
            "Compression time: 151.000 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1324.62 bytes\n",
            "   Compression Ratio: 7.398x\n",
            "   Bits Per Byte:    1.081 bpb\n",
            "   Speed:            64.90 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.1151 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.1282 bits/token\n",
            "   Overhead:         0.0130 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 172.533 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile alice_10k.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hlMNrGdfdHQ0",
        "outputId": "32a93799-20fa-4f86-a36a-2e61ac30b7e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 07:03:57.643046: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 07:03:57.661471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764745437.684080   33981 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764745437.690649   33981 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764745437.707470   33981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745437.707498   33981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745437.707501   33981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745437.707504   33981 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 07:03:57.712380: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 2567 tokens...\n",
            "Compression time: 151.485 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1284.62 bytes\n",
            "   Compression Ratio: 7.629x\n",
            "   Bits Per Byte:    1.049 bpb\n",
            "   Speed:            64.69 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.9907 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.0035 bits/token\n",
            "   Overhead:         0.0128 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 174.890 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile alice_10k.txt --context-size 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t4Ao52eGHFHF",
        "outputId": "414f3a57-09cf-495e-c0bd-6d91746a6f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-05 01:52:54.724136: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 01:52:54.741248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764899574.762014    3098 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764899574.768379    3098 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764899574.784331    3098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899574.784358    3098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899574.784361    3098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764899574.784364    3098 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 01:52:54.789123: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 2567 tokens...\n",
            "Compression time: 149.402 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1252.00 bytes\n",
            "   Compression Ratio: 7.827x\n",
            "   Bits Per Byte:    1.022 bpb\n",
            "   Speed:            65.59 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.8887 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.9018 bits/token\n",
            "   Overhead:         0.0131 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 171.784 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile alice_10k.txt --context-size 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ehhceHip4iIW",
        "outputId": "edbbf6cf-803c-45ae-cb17-045b801d8204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-03 07:09:40.564935: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 07:09:40.583116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764745780.604373   35461 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764745780.610918   35461 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764745780.627699   35461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745780.627738   35461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745780.627741   35461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764745780.627744   35461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-03 07:09:40.632608: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: alice_10k.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 2567 tokens...\n",
            "Compression time: 155.152 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  1227.50 bytes\n",
            "   Compression Ratio: 7.984x\n",
            "   Bits Per Byte:    1.002 bpb\n",
            "   Speed:            63.16 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.8126 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.8255 bits/token\n",
            "   Overhead:         0.0129 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 178.173 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "Match exact: True\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model mamba --infile alice_10k.txt --context-size 3000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn5XbfVAgJE6"
      },
      "source": [
        "Test precision settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j1zzZ4CwNg6N",
        "outputId": "979b3ad0-40dd-4597-a5d8-a47308ed89d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-29 04:34:16.140390: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764390856.160193   53040 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764390856.166197   53040 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764390856.185199   53040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764390856.185227   53040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764390856.185231   53040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764390856.185235   53040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-29 04:34:16.192301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Loading Model: tinyllama (dtype=fp32) ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float32).\n",
            "=== Compressing ===\n",
            "Compression time: 120.707 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    9800 bytes\n",
            "   Compressed Size:  925.62 bytes\n",
            "   Compression Ratio: 10.587x\n",
            "   Bits Per Byte:    0.756 bpb\n",
            "   Speed:            20.7 tokens/sec\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  2.8961 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  2.9620 bits/token\n",
            "   Overhead:         0.0659 bits/token\n",
            "   Model Uncertainty: 2.8627 bits (Avg Entropy)\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing and verifying ===\n",
            "\n",
            "Recovered text snippet: \n",
            "\n",
            "\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "            \n",
            "\n",
            "Match exact: False\n",
            "\n",
            "Decompression time: 135.711 sec\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --infile alice_10k.txt --dtype fp32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNtXJL4SfOTz"
      },
      "source": [
        "Test different datasets using different models.\n",
        "Compression of:\n",
        "1. Movie review of Zootopia 2 (Latest review and probably not used to train the model)\n",
        "2. Walmart Product description\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm_compressor.py --model tinyllama --infile movie_review.txt"
      ],
      "metadata": {
        "id": "jw3tweRv9Bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "50cf2cef-4719-4abf-a8a4-3d10dcafe991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-12 05:39:46.969102: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-12 05:39:46.987264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765517987.008638    1993 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765517987.015125    1993 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765517987.031909    1993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765517987.031948    1993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765517987.031951    1993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765517987.031954    1993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-12 05:39:47.036809: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: movie_review.txt ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3278 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Processing 3278 tokens...\n",
            "Compression time: 148.165 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    12056 bytes\n",
            "   Compressed Size:  1522.88 bytes\n",
            "   Compression Ratio: 7.917x\n",
            "   Bits Per Byte:    1.011 bpb\n",
            "   Speed:            81.37 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.7065 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.7166 bits/token\n",
            "   Overhead:         0.0101 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 164.735 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "Focus Reset\n",
            "Upgrade to \n",
            "No ads, unlimited game maps,\n",
            "free games, discounts and more\n",
            "See all the benefits\n",
            "Home\n",
            "\n",
            "Search\n",
            "\n",
            "Reviews\n",
            "\n",
            "News\n",
            "Guides\n",
            "Interactive Maps\n",
            "Playlist\n",
            "\n",
            "Discover\n",
            "Store\n",
            "Rewards\n",
            "\n",
            "Videos\n",
            "P\n",
            "Match exact: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm_compressor.py --model tinyllama --infile product.txt"
      ],
      "metadata": {
        "id": "Kh7n5Qp-9T3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41da4965-4013-4643-aa1d-2ff868913e09",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-12 05:45:18.969199: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-12 05:45:18.986934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765518319.008145    3429 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765518319.014593    3429 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765518319.030918    3429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518319.030949    3429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518319.030952    3429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518319.030955    3429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-12 05:45:19.035837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: product.txt ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Processing 605 tokens...\n",
            "Compression time: 27.257 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    2252 bytes\n",
            "   Compressed Size:  215.38 bytes\n",
            "   Compression Ratio: 10.456x\n",
            "   Bits Per Byte:    0.765 bpb\n",
            "   Speed:            82.62 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  2.7925 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  2.8479 bits/token\n",
            "   Overhead:         0.0554 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded tinyllama (TinyLlama/TinyLlama-1.1B-Chat-v1.0) model with ~1,100,048,384 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 29.645 sec\n",
            "\n",
            "Recovered text snippet: BalanceFrom Stair Climber Commercial Grade Stair Stepper Machine for Cardio and Lower Body Workouts\n",
            "\n",
            "About this item\n",
            "\n",
            "Product details\n",
            "\n",
            "Elevate your cardio workouts and enhance lower body strength with\n",
            "Match exact: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm_compressor.py --model mamba --infile movie_review.txt"
      ],
      "metadata": {
        "id": "7cN_p-ub9Hxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe54d46-6c28-48cd-fdb6-bd84260e5614",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-09 07:16:57.480547: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-09 07:16:57.497938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765264617.518905    2796 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765264617.525286    2796 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765264617.541608    2796 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765264617.541636    2796 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765264617.541639    2796 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765264617.541641    2796 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-09 07:16:57.546616: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: movie_review.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 100% 156/156 [00:00<00:00, 756kB/s]\n",
            "vocab.json: 1.08MB [00:00, 14.2MB/s]\n",
            "merges.txt: 457kB [00:00, 34.4MB/s]\n",
            "tokenizer.json: 2.11MB [00:00, 68.4MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 623kB/s]\n",
            "config.json: 100% 895/895 [00:00<00:00, 8.69MB/s]\n",
            "model.safetensors: 100% 517M/517M [00:02<00:00, 224MB/s]\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 1.19MB/s]\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 2917 tokens...\n",
            "Compression time: 176.880 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    12056 bytes\n",
            "   Compressed Size:  1828.00 bytes\n",
            "   Compression Ratio: 6.595x\n",
            "   Bits Per Byte:    1.213 bpb\n",
            "   Speed:            68.16 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  5.0035 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  5.0134 bits/token\n",
            "   Overhead:         0.0099 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 203.257 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "Focus Reset\n",
            "Upgrade to \n",
            "No ads, unlimited game maps,\n",
            "free games, discounts and more\n",
            "See all the benefits\n",
            "Home\n",
            "\n",
            "Search\n",
            "\n",
            "Reviews\n",
            "\n",
            "News\n",
            "Guides\n",
            "Interactive Maps\n",
            "Playlist\n",
            "\n",
            "Discover\n",
            "Store\n",
            "Rewards\n",
            "\n",
            "Videos\n",
            "P\n",
            "Match exact: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm_compressor.py --model mamba --infile product.txt"
      ],
      "metadata": {
        "id": "EaCNAkTu9y2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff730912-9b88-47b4-c8f2-c9adef291307",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-09 07:23:36.221271: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-09 07:23:36.239119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765265016.260882    4509 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765265016.267472    4509 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765265016.283916    4509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765265016.283946    4509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765265016.283949    4509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765265016.283952    4509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-09 07:23:36.288906: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: product.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Processing 495 tokens...\n",
            "Compression time: 30.174 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    2252 bytes\n",
            "   Compressed Size:  269.75 bytes\n",
            "   Compression Ratio: 8.348x\n",
            "   Bits Per Byte:    0.958 bpb\n",
            "   Speed:            74.63 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.2927 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.3596 bits/token\n",
            "   Overhead:         0.0669 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loaded mamba (state-spaces/mamba-130m-hf) model with ~129,135,360 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 33.894 sec\n",
            "\n",
            "Recovered text snippet: BalanceFrom Stair Climber Commercial Grade Stair Stepper Machine for Cardio and Lower Body Workouts\n",
            "\n",
            "About this item\n",
            "\n",
            "Product details\n",
            "\n",
            "Elevate your cardio workouts and enhance lower body strength with\n",
            "Match exact: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm_compressor.py --model mamba1.4b --infile movie_review.txt"
      ],
      "metadata": {
        "id": "z9bAv9nu9Pba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d6ca1f82-fcab-4f2b-f765-442e0849ed67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-12 05:46:34.096423: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-12 05:46:34.115709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765518394.136977    3791 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765518394.143446    3791 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765518394.160035    3791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518394.160067    3791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518394.160070    3791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518394.160073    3791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-12 05:46:34.164906: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: movie_review.txt ===\n",
            "Selected device: cuda\n",
            "tokenizer_config.json: 100% 156/156 [00:00<00:00, 785kB/s]\n",
            "vocab.json: 1.08MB [00:00, 24.5MB/s]\n",
            "merges.txt: 457kB [00:00, 53.7MB/s]\n",
            "tokenizer.json: 2.11MB [00:00, 95.3MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 486kB/s]\n",
            "config.json: 100% 879/879 [00:00<00:00, 7.46MB/s]\n",
            "model.safetensors.index.json: 38.2kB [00:00, 119MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/528M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 2.04M/4.96G [00:02<1:21:53, 1.01MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 221k/528M [00:02<1:22:22, 107kB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 2.17M/4.96G [00:02<1:21:00, 1.02MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.96G [00:02<01:02, 77.9MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 192M/4.96G [00:02<00:27, 174MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 260M/4.96G [00:02<00:20, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 322M/4.96G [00:02<00:16, 286MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 393M/4.96G [00:02<00:13, 348MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 102M/528M [00:03<00:11, 38.7MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 109M/528M [00:03<00:13, 31.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 115M/528M [00:04<00:12, 32.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 513M/4.96G [00:04<00:28, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.96G [00:04<00:18, 235MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 707M/4.96G [00:04<00:15, 268MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 134M/528M [00:04<00:11, 32.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 813M/4.96G [00:04<00:14, 289MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 893M/4.96G [00:04<00:12, 337MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 952M/4.96G [00:04<00:10, 369MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 170M/528M [00:04<00:07, 47.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.96G [00:04<00:09, 406MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 200M/528M [00:05<00:05, 64.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.96G [00:05<00:09, 413MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 234M/528M [00:05<00:03, 80.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.96G [00:05<00:07, 510MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.96G [00:05<00:06, 552MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.96G [00:05<00:07, 475MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 338M/528M [00:07<00:03, 52.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.96G [00:07<00:34, 103MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 461M/528M [00:07<00:00, 103MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.96G [00:07<00:19, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.96G [00:07<00:12, 257MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 528M/528M [00:08<00:00, 65.3MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.96G [00:08<00:10, 304MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.96G [00:08<00:06, 465MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.11G/4.96G [00:08<00:05, 556MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.96G [00:08<00:04, 548MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.96G [00:08<00:04, 551MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.96G [00:09<00:05, 477MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.52G/4.96G [00:09<00:10, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.96G [00:10<00:11, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.96G [00:10<00:10, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.96G [00:10<00:10, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.96G [00:10<00:08, 251MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.96G [00:11<00:09, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.96G [00:11<00:14, 149MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.96G [00:11<00:04, 402MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.96G [00:11<00:03, 485MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.35G/4.96G [00:12<00:02, 623MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.45G/4.96G [00:12<00:02, 666MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.56G/4.96G [00:12<00:01, 708MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.96G [00:12<00:01, 875MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.96G [00:12<00:01, 606MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.96G [00:13<00:02, 445MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.96G [00:13<00:01, 506MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.15G/4.96G [00:13<00:01, 459MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.96G [00:13<00:01, 446MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 4.30G/4.96G [00:15<00:05, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.96G [00:16<00:04, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.96G [00:16<00:02, 203MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.96G [00:16<00:01, 274MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.96G [00:16<00:00, 449MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.96G [00:16<00:00, 297MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:17<00:00,  8.70s/it]\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.70it/s]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 1.17MB/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Processing 2917 tokens...\n",
            "Compression time: 256.363 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    12056 bytes\n",
            "   Compressed Size:  1577.62 bytes\n",
            "   Compression Ratio: 7.642x\n",
            "   Bits Per Byte:    1.047 bpb\n",
            "   Speed:            47.03 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  4.3282 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  4.3267 bits/token\n",
            "   Overhead:         -0.0015 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  4.06it/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 283.066 sec\n",
            "\n",
            "Recovered text snippet: \n",
            "Focus Reset\n",
            "Upgrade to \n",
            "No ads, unlimited game maps,\n",
            "free games, discounts and more\n",
            "See all the benefits\n",
            "Home\n",
            "\n",
            "Search\n",
            "\n",
            "Reviews\n",
            "\n",
            "News\n",
            "Guides\n",
            "Interactive Maps\n",
            "Playlist\n",
            "\n",
            "Discover\n",
            "Store\n",
            "Rewards\n",
            "\n",
            "Videos\n",
            "P\n",
            "Match exact: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm_compressor.py --model mamba1.4b --infile product.txt"
      ],
      "metadata": {
        "id": "bpZsQLgi9zWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6d156eae-80c4-4197-91b0-dbc7abe305a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-12 05:56:15.749224: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-12 05:56:15.766846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765518975.788267    6294 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765518975.794751    6294 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765518975.811273    6294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518975.811315    6294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518975.811318    6294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765518975.811321    6294 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-12 05:56:15.816176: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== Compressing: product.txt ===\n",
            "Selected device: cuda\n",
            "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  4.10it/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Processing 495 tokens...\n",
            "Compression time: 43.953 sec\n",
            "\n",
            "============================================================\n",
            "                  FINAL COMPRESSION REPORT                  \n",
            "============================================================\n",
            "1. EFFICIENCY\n",
            "   Original Size:    2252 bytes\n",
            "   Compressed Size:  224.50 bytes\n",
            "   Compression Ratio: 10.031x\n",
            "   Bits Per Byte:    0.798 bpb\n",
            "   Speed:            51.24 B/s\n",
            "\n",
            "2. ENTROPY\n",
            "   LLM Theoretical:  3.5607 bits/token (Cross-Entropy)\n",
            "   Actual SCL Code:  3.6283 bits/token\n",
            "   Overhead:         0.0675 bits/token\n",
            "============================================================\n",
            "\n",
            "Saved compressed file to out.sclbit\n",
            "\n",
            "=== Decompressing: out.sclbit ===\n",
            "Selected device: cuda\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  4.03it/s]\n",
            "Loaded mamba1.4b (state-spaces/mamba-1.4b-hf) model with ~1,372,178,432 parameters (dtype=torch.float16).\n",
            "Decoding...\n",
            "Decompression time: 48.271 sec\n",
            "\n",
            "Recovered text snippet: BalanceFrom Stair Climber Commercial Grade Stair Stepper Machine for Cardio and Lower Body Workouts\n",
            "\n",
            "About this item\n",
            "\n",
            "Product details\n",
            "\n",
            "Elevate your cardio workouts and enhance lower body strength with\n",
            "Match exact: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QyJQrlFVQEn"
      },
      "source": [
        "Llama3 test. Do take note to login huggingface by running the below cell and enter token value in the --hf-token argument.\n",
        "\n",
        "However, testing of this model was discontinued due to its long run times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9PVeb_EmR5Az",
        "outputId": "0d230985-144d-4250-9f5a-e63b9903795e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `hf auth whoami` to get more information or `hf auth logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: read).\n",
            "The token `EE274 project` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `EE274 project`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5Q-Av_85PPnl",
        "outputId": "7f9e172c-110a-457d-cf5c-004c79e575fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "model-00022-of-00030.safetensors:   0% 0.00/4.66G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00014-of-00030.safetensors:  99% 4.90G/4.97G [18:21<00:09, 7.22MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:   6% 269M/4.66G [01:20<13:36, 5.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  14% 672M/4.97G [02:37<09:29, 7.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  24% 1.21G/5.00G [05:29<07:38, 8.26MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  23% 1.07G/4.66G [06:27<11:34, 5.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:   7% 336M/4.66G [01:29<12:13, 5.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00014-of-00030.safetensors: 100% 4.97G/4.97G [18:30<00:00, 4.47MB/s]\n",
            "Fetching 30 files:  47% 14/30 [38:16<24:37, 92.37s/it] \n",
            "\n",
            "model-00023-of-00030.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00016-of-00030.safetensors:  97% 4.53G/4.66G [17:50<00:30, 4.44MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  25% 1.27G/5.00G [05:39<08:01, 7.74MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  26% 1.21G/4.66G [06:38<08:04, 7.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00016-of-00030.safetensors:  99% 4.60G/4.66G [17:57<00:16, 4.18MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  15% 739M/4.97G [02:50<10:21, 6.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  27% 1.34G/5.00G [05:43<06:34, 9.28MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:   7% 336M/4.66G [01:40<12:13, 5.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  28% 1.31G/4.66G [06:47<06:45, 8.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:   9% 403M/4.66G [01:46<13:43, 5.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00016-of-00030.safetensors:  99% 4.60G/4.66G [18:10<00:16, 4.18MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  28% 1.41G/5.00G [05:54<06:26, 9.28MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  15% 739M/4.97G [03:02<10:21, 6.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  16% 806M/4.97G [03:04<11:25, 6.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  29% 1.47G/5.00G [05:56<06:11, 9.49MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  30% 1.38G/4.66G [06:55<06:38, 8.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   0% 720k/4.66G [00:35<63:10:09, 20.5kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  10% 470M/4.66G [01:55<12:23, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  32% 1.60G/5.00G [05:59<04:15, 13.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  31% 1.45G/4.66G [07:01<06:07, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  14% 672M/4.66G [02:01<06:07, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  33% 1.67G/5.00G [06:10<05:09, 10.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  19% 940M/4.97G [03:18<09:20, 7.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00016-of-00030.safetensors: 100% 4.66G/4.66G [18:30<00:00, 4.20MB/s]\n",
            "Fetching 30 files:  53% 16/30 [38:57<14:51, 63.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  32% 1.51G/4.66G [07:11<05:59, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   0% 720k/4.66G [00:50<63:10:09, 20.5kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  34% 1.58G/4.66G [07:17<06:02, 8.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   1% 67.8M/4.66G [00:56<52:27, 1.46MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  16% 739M/4.66G [02:20<06:01, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  36% 1.80G/5.00G [06:24<04:57, 10.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  20% 1.01G/4.97G [03:32<09:11, 7.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  22% 1.07G/4.97G [03:39<09:21, 6.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:   1% 67.0M/4.66G [01:17<1:29:06, 860kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  35% 1.65G/4.66G [07:28<06:25, 7.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   3% 135M/4.66G [01:09<30:04, 2.51MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  37% 1.84G/5.00G [06:34<05:57, 8.83MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  24% 1.17G/4.97G [03:42<07:12, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   1% 67.1M/5.00G [01:01<1:14:57, 1.10MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  38% 1.78G/4.66G [07:41<06:07, 7.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   3% 135M/4.66G [01:20<30:04, 2.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:   1% 67.0M/4.66G [01:30<1:29:06, 860kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  17% 806M/4.66G [02:42<10:46, 5.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  38% 1.92G/5.00G [06:47<06:24, 8.01MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  28% 1.37G/4.97G [04:00<06:04, 9.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   2% 118M/5.00G [01:18<50:00, 1.63MB/s]   \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:   3% 134M/4.66G [01:42<52:04, 1.45MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  40% 1.85G/4.66G [07:58<06:30, 7.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   4% 202M/4.66G [01:39<30:59, 2.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  19% 873M/4.66G [03:00<11:50, 5.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  38% 1.92G/5.00G [07:04<06:24, 8.01MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  29% 1.44G/4.97G [04:12<05:57, 9.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   2% 118M/5.00G [01:30<50:00, 1.63MB/s]\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  40% 1.99G/5.00G [07:04<07:45, 6.47MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:   4% 201M/4.66G [01:52<33:07, 2.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  44% 2.05G/4.66G [08:03<03:57, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  20% 940M/4.66G [03:10<11:37, 5.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   4% 202M/4.66G [01:50<30:59, 2.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  22% 1.01G/4.66G [03:12<09:15, 6.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  41% 2.05G/5.00G [07:15<07:43, 6.36MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  30% 1.48G/4.97G [04:28<08:28, 6.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:   6% 268M/4.66G [02:07<26:18, 2.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  45% 2.12G/4.66G [08:18<04:50, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  23% 1.07G/4.66G [03:22<09:06, 6.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  42% 2.12G/5.00G [07:27<07:48, 6.14MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  32% 1.61G/4.97G [04:38<06:48, 8.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   4% 185M/5.00G [01:57<47:44, 1.68MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:   9% 402M/4.66G [02:20<15:43, 4.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  45% 2.12G/4.66G [08:31<04:50, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   6% 269M/4.66G [02:11<32:15, 2.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  44% 2.19G/5.00G [07:36<07:05, 6.60MB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   5% 252M/5.00G [02:02<30:24, 2.60MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  24% 1.14G/4.66G [03:40<08:56, 6.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  34% 1.69G/4.97G [04:52<06:38, 8.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  10% 470M/4.66G [02:30<15:28, 4.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:   9% 403M/4.66G [02:22<17:51, 3.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  26% 1.21G/4.66G [03:45<09:07, 6.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  48% 2.39G/5.00G [07:52<05:01, 8.64MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  35% 1.76G/4.97G [05:01<07:04, 7.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   6% 319M/5.00G [02:20<29:59, 2.60MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   8% 386M/5.00G [02:24<20:10, 3.81MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  12% 537M/4.66G [02:47<14:32, 4.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  47% 2.18G/4.66G [08:58<08:26, 4.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  26% 1.21G/4.66G [04:00<09:07, 6.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  10% 470M/4.66G [02:40<17:34, 3.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  48% 2.39G/5.00G [08:04<05:01, 8.64MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  35% 1.76G/4.97G [05:12<07:04, 7.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  27% 1.27G/4.66G [04:01<09:55, 5.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  37% 1.83G/4.97G [05:14<07:35, 6.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   9% 453M/5.00G [02:33<17:09, 4.42MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  13% 604M/4.66G [02:53<12:24, 5.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  50% 2.32G/4.66G [09:11<07:58, 4.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:   1% 67.0M/4.97G [02:02<2:29:03, 548kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  12% 537M/4.66G [02:52<16:33, 4.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  30% 1.41G/4.66G [04:13<07:49, 6.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  16% 738M/4.66G [03:10<10:22, 6.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  51% 2.38G/4.66G [09:20<06:11, 6.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  37% 1.83G/4.97G [05:32<07:35, 6.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:   9% 453M/5.00G [02:50<17:09, 4.42MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:   4% 201M/4.97G [02:12<42:16, 1.88MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  32% 1.48G/4.66G [04:27<08:26, 6.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  10% 520M/5.00G [03:00<20:39, 3.61MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  53% 2.45G/4.66G [09:31<06:00, 6.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  12% 537M/4.66G [03:10<16:33, 4.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  16% 738M/4.66G [03:20<10:22, 6.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  17% 806M/4.66G [03:25<11:16, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  13% 604M/4.66G [03:19<18:51, 3.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  33% 1.54G/4.66G [04:40<08:15, 6.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:   5% 260M/4.97G [02:29<41:44, 1.88MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  11% 529M/5.00G [03:10<20:37, 3.61MB/s]\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  48% 2.42G/5.00G [08:48<12:42, 3.39MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  38% 1.89G/4.97G [05:57<12:28, 4.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  12% 596M/5.00G [03:20<20:04, 3.65MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  54% 2.52G/4.66G [09:51<06:31, 5.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  14% 671M/4.66G [03:30<18:33, 3.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  17% 806M/4.66G [03:40<11:16, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  35% 1.61G/4.66G [04:51<08:27, 6.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  54% 2.68G/5.00G [08:55<05:32, 6.96MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  16% 738M/4.66G [03:38<14:29, 4.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  39% 1.95G/4.97G [06:10<12:19, 4.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  13% 672M/5.00G [03:29<16:11, 4.46MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  56% 2.62G/4.66G [10:00<05:28, 6.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:   7% 327M/4.97G [02:48<31:40, 2.44MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  19% 873M/4.66G [03:50<14:01, 4.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  36% 1.68G/4.66G [05:00<07:59, 6.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  58% 2.68G/4.66G [10:07<04:58, 6.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:   8% 394M/4.97G [02:56<24:53, 3.06MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  20% 940M/4.66G [03:58<12:02, 5.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  16% 738M/4.66G [03:50<14:29, 4.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  54% 2.68G/5.00G [09:14<05:32, 6.96MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  39% 1.95G/4.97G [06:22<12:19, 4.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  15% 739M/5.00G [03:40<15:56, 4.46MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  17% 805M/4.66G [03:52<14:10, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  41% 2.01G/4.97G [06:29<12:26, 3.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  16% 806M/5.00G [03:47<12:58, 5.39MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  43% 2.15G/4.97G [06:29<06:59, 6.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  60% 2.82G/4.66G [10:18<03:53, 7.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  22% 1.01G/4.66G [04:08<11:14, 5.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  55% 2.75G/5.00G [09:22<07:00, 5.34MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  36% 1.68G/4.66G [05:20<07:59, 6.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  11% 528M/4.97G [03:09<24:09, 3.06MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  12% 595M/4.97G [03:10<13:38, 5.34MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  45% 2.22G/4.97G [06:33<05:50, 7.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  62% 2.89G/4.66G [10:23<03:22, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  37% 1.74G/4.66G [05:22<09:39, 5.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  58% 2.89G/5.00G [09:27<04:50, 7.28MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  20% 940M/4.66G [04:03<10:13, 6.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  19% 940M/5.00G [03:54<09:02, 7.48MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  46% 2.28G/4.97G [06:39<05:16, 8.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  13% 662M/4.97G [03:16<12:11, 5.88MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  23% 1.07G/4.66G [04:18<10:30, 5.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  40% 1.88G/4.66G [05:33<06:58, 6.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  22% 1.01G/4.66G [04:19<11:01, 5.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  62% 2.89G/4.66G [10:41<03:22, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  13% 662M/4.97G [03:29<12:11, 5.88MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  59% 2.93G/5.00G [09:44<04:43, 7.28MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  46% 2.28G/4.97G [06:52<05:16, 8.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  19% 940M/5.00G [04:10<09:02, 7.48MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  24% 1.14G/4.66G [04:31<10:18, 5.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  47% 2.35G/4.97G [06:57<06:54, 6.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  15% 729M/4.97G [03:34<13:35, 5.20MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  40% 1.88G/4.66G [05:50<06:58, 6.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  22% 1.01G/4.66G [04:30<11:01, 5.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  63% 2.95G/4.66G [10:52<05:20, 5.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  26% 1.21G/4.66G [04:42<10:05, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  42% 1.95G/4.66G [05:51<08:07, 5.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  23% 1.07G/4.66G [04:34<11:32, 5.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  20% 1.01G/5.00G [04:25<13:47, 4.82MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  15% 756M/4.97G [03:45<15:04, 4.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  65% 3.02G/4.66G [10:57<04:21, 6.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  45% 2.08G/4.66G [06:00<05:44, 7.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  47% 2.35G/4.97G [07:12<06:54, 6.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  23% 1.08G/4.66G [04:45<14:44, 4.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  60% 3.00G/5.00G [10:10<06:47, 4.90MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  45% 2.08G/4.66G [06:10<05:44, 7.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  65% 3.02G/4.66G [11:11<04:21, 6.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  17% 823M/4.97G [03:59<14:50, 4.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  20% 1.01G/5.00G [04:40<13:47, 4.82MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  27% 1.27G/4.66G [05:01<09:53, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  18% 873M/4.97G [04:05<13:20, 5.12MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  66% 3.09G/4.66G [11:18<05:11, 5.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  24% 1.14G/4.66G [05:00<14:27, 4.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  60% 3.00G/5.00G [10:24<06:47, 4.90MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  29% 1.34G/4.66G [05:13<10:50, 5.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  46% 2.15G/4.66G [06:22<07:26, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  61% 3.07G/5.00G [10:28<07:02, 4.57MB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  21% 1.07G/5.00G [04:56<17:27, 3.75MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  49% 2.42G/4.97G [07:38<11:58, 3.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  68% 3.15G/4.66G [11:31<04:58, 5.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  19% 940M/4.97G [04:19<13:07, 5.12MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  20% 1.01G/4.97G [04:22<11:03, 5.97MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  47% 2.21G/4.66G [06:36<07:35, 5.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  26% 1.21G/4.66G [05:16<13:44, 4.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  63% 3.13G/5.00G [10:44<06:48, 4.57MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  50% 2.48G/4.97G [07:52<11:39, 3.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  22% 1.10G/5.00G [05:10<17:20, 3.75MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  29% 1.34G/4.66G [05:31<10:50, 5.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  23% 1.16G/5.00G [05:13<15:20, 4.17MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  51% 2.55G/4.97G [07:55<08:34, 4.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  68% 3.19G/4.66G [11:50<05:47, 4.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  49% 2.28G/4.66G [06:50<07:22, 5.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  20% 1.01G/4.97G [04:39<11:03, 5.97MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  27% 1.28G/4.66G [05:30<13:28, 4.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  30% 1.41G/4.66G [05:43<13:44, 3.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  29% 1.34G/4.66G [05:33<10:35, 5.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  49% 2.30G/4.66G [06:54<07:20, 5.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  54% 2.68G/4.97G [08:11<06:44, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  22% 1.07G/4.97G [04:48<14:14, 4.55MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  32% 1.48G/4.66G [05:50<11:34, 4.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  68% 3.19G/4.66G [12:01<05:47, 4.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  25% 1.23G/5.00G [05:30<15:04, 4.17MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  30% 1.41G/4.66G [05:45<10:12, 5.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  64% 3.20G/5.00G [11:09<07:27, 4.02MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  51% 2.37G/4.66G [07:09<07:32, 5.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  26% 1.30G/5.00G [05:39<13:48, 4.47MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  22% 1.07G/4.97G [04:59<14:14, 4.55MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  54% 2.68G/4.97G [08:22<06:44, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  33% 1.54G/4.66G [06:01<11:20, 4.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  69% 3.20G/4.66G [12:17<08:39, 2.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  23% 1.14G/4.97G [05:09<15:17, 4.17MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  51% 2.37G/4.66G [07:20<07:32, 5.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  30% 1.41G/4.66G [06:00<10:12, 5.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  65% 3.27G/5.00G [11:24<07:10, 4.02MB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  27% 1.37G/5.00G [05:50<13:33, 4.47MB/s]\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  67% 3.34G/5.00G [11:28<05:54, 4.69MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  52% 2.44G/4.66G [07:24<07:36, 4.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  29% 1.43G/5.00G [05:55<11:00, 5.40MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  55% 2.75G/4.97G [08:37<08:15, 4.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  70% 3.27G/4.66G [12:27<06:46, 3.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  24% 1.21G/4.97G [05:15<12:39, 4.95MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  35% 1.61G/4.66G [06:22<11:30, 4.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  52% 2.44G/4.66G [07:40<07:36, 4.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  73% 3.40G/4.66G [12:41<06:07, 3.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  24% 1.21G/4.97G [05:29<12:39, 4.95MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  67% 3.34G/5.00G [11:44<05:54, 4.69MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  55% 2.75G/4.97G [08:52<08:15, 4.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  29% 1.43G/5.00G [06:10<11:00, 5.40MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  54% 2.51G/4.66G [07:42<07:54, 4.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  57% 2.82G/4.97G [08:54<08:14, 4.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  74% 3.47G/4.66G [12:49<03:45, 5.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  35% 1.61G/4.66G [06:41<11:30, 4.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  26% 1.27G/4.97G [05:41<15:38, 3.93MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  36% 1.68G/4.66G [06:45<12:28, 3.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  32% 1.48G/4.66G [06:34<17:05, 3.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  68% 3.40G/5.00G [12:02<07:11, 3.70MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  55% 2.55G/4.66G [07:58<08:52, 3.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  74% 3.47G/4.66G [13:01<03:45, 5.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  58% 2.87G/4.97G [09:12<08:03, 4.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  30% 1.50G/5.00G [06:35<15:39, 3.73MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  76% 3.54G/4.66G [13:10<04:00, 4.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  55% 2.55G/4.66G [08:10<08:52, 3.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  27% 1.34G/4.97G [05:59<15:21, 3.93MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  33% 1.54G/4.66G [06:50<16:44, 3.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  68% 3.40G/5.00G [12:14<07:11, 3.70MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  37% 1.74G/4.66G [07:01<12:11, 3.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  76% 3.54G/4.66G [13:21<04:00, 4.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  30% 1.50G/5.00G [06:50<15:39, 3.73MB/s]\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  69% 3.47G/5.00G [12:25<07:14, 3.52MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  56% 2.62G/4.66G [08:21<09:28, 3.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  31% 1.57G/5.00G [06:54<15:33, 3.68MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  59% 2.93G/4.97G [09:37<09:30, 3.56MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  28% 1.41G/4.97G [06:14<14:51, 3.99MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  35% 1.61G/4.66G [07:05<14:30, 3.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  58% 2.68G/4.66G [08:32<07:58, 4.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  32% 1.58G/5.00G [07:07<18:28, 3.09MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  62% 3.07G/4.97G [09:51<06:45, 4.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  30% 1.48G/4.97G [06:29<14:35, 3.99MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  37% 1.75G/4.66G [07:20<13:52, 3.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  71% 3.54G/5.00G [12:44<06:55, 3.52MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  77% 3.60G/4.66G [13:42<04:55, 3.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  39% 1.81G/4.66G [07:25<09:25, 5.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  39% 1.81G/4.66G [07:36<14:21, 3.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  71% 3.55G/5.00G [12:50<07:05, 3.41MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  58% 2.68G/4.66G [08:50<07:58, 4.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  63% 3.14G/4.97G [10:02<06:31, 4.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  32% 1.58G/5.00G [07:20<18:28, 3.09MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  58% 2.72G/4.66G [08:52<09:33, 3.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  33% 1.64G/5.00G [07:22<16:13, 3.45MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  64% 3.20G/4.97G [10:08<05:23, 5.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  79% 3.67G/4.66G [13:57<04:20, 3.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  31% 1.53G/4.97G [06:46<14:43, 3.89MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  39% 1.81G/4.66G [07:40<09:25, 5.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  72% 3.62G/5.00G [13:04<06:46, 3.41MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  40% 1.88G/4.66G [07:51<14:01, 3.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  42% 1.95G/4.66G [07:52<10:45, 4.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  74% 3.68G/5.00G [13:06<04:55, 4.45MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  60% 2.79G/4.66G [09:06<08:23, 3.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  34% 1.71G/5.00G [07:38<15:11, 3.61MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  80% 3.74G/4.66G [14:11<04:03, 3.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  31% 1.53G/4.97G [06:59<14:43, 3.89MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  64% 3.20G/4.97G [10:22<05:23, 5.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  82% 3.80G/4.66G [14:14<02:56, 4.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  43% 2.01G/4.66G [08:09<10:32, 4.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  75% 3.75G/5.00G [13:22<04:45, 4.37MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  61% 2.86G/4.66G [09:18<07:17, 4.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  34% 1.71G/5.00G [07:50<15:11, 3.61MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  36% 1.78G/5.00G [07:54<14:17, 3.76MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  61% 2.86G/4.66G [09:30<07:17, 4.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  82% 3.80G/4.66G [14:31<02:56, 4.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  75% 3.75G/5.00G [13:34<04:45, 4.37MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  43% 2.01G/4.66G [08:21<10:32, 4.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  83% 3.87G/4.66G [14:32<02:54, 4.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  32% 1.59G/4.97G [07:20<17:36, 3.19MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  45% 2.08G/4.66G [08:27<10:38, 4.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  76% 3.82G/5.00G [13:42<04:51, 4.05MB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  37% 1.83G/5.00G [08:10<14:01, 3.76MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  62% 2.90G/4.66G [09:44<09:32, 3.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  40% 1.88G/4.66G [08:29<15:33, 2.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  84% 3.90G/4.66G [14:51<02:47, 4.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  33% 1.66G/4.97G [07:39<17:15, 3.19MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  78% 3.88G/5.00G [13:54<04:35, 4.05MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  45% 2.08G/4.66G [08:41<10:38, 4.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  46% 2.15G/4.66G [08:43<10:20, 4.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  79% 3.95G/5.00G [13:57<03:21, 5.22MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  65% 3.22G/4.97G [11:10<11:07, 2.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  62% 2.90G/4.66G [10:00<09:32, 3.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  43% 2.01G/4.66G [08:40<14:48, 2.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  84% 3.90G/4.66G [15:03<04:07, 3.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  35% 1.73G/4.97G [07:52<15:25, 3.50MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  45% 2.08G/4.66G [08:43<09:25, 4.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  80% 4.02G/5.00G [14:11<03:12, 5.11MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  64% 2.97G/4.66G [10:08<09:25, 3.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  66% 3.29G/4.97G [11:22<10:41, 2.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  47% 2.21G/4.66G [09:01<10:03, 4.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  68% 3.36G/4.97G [11:25<07:23, 3.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  36% 1.79G/4.97G [08:07<14:17, 3.70MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  48% 2.22G/4.66G [08:58<07:37, 5.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  64% 2.97G/4.66G [10:20<09:25, 3.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  85% 3.97G/4.66G [15:21<03:46, 3.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  82% 4.09G/5.00G [14:24<02:59, 5.11MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  49% 2.28G/4.66G [09:12<09:16, 4.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  65% 3.03G/4.66G [10:26<08:30, 3.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  38% 1.90G/5.00G [08:56<18:58, 2.72MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  87% 4.04G/4.66G [15:28<02:45, 3.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  49% 2.28G/4.66G [09:07<07:04, 5.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  83% 4.15G/5.00G [14:34<02:36, 5.41MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  36% 1.79G/4.97G [08:19<14:17, 3.70MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  68% 3.36G/4.97G [11:42<07:23, 3.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  66% 3.06G/4.66G [10:31<07:52, 3.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  69% 3.42G/4.97G [11:44<07:09, 3.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  89% 4.13G/4.66G [15:34<01:47, 5.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  37% 1.86G/4.97G [08:27<14:24, 3.59MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  84% 4.22G/5.00G [14:43<02:14, 5.79MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  70% 3.26G/4.66G [10:39<03:13, 7.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  50% 2.35G/4.66G [09:20<06:53, 5.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  39% 1.97G/5.00G [09:10<18:33, 2.72MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  50% 2.35G/4.66G [09:31<09:01, 4.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  41% 2.04G/5.00G [09:13<13:15, 3.73MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  72% 3.56G/4.97G [11:55<04:43, 4.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  39% 1.93G/4.97G [08:34<11:43, 4.32MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  52% 2.41G/4.66G [09:39<08:15, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  70% 3.26G/4.66G [10:50<03:13, 7.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  89% 4.13G/4.66G [15:51<01:47, 5.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  84% 4.22G/5.00G [14:54<02:14, 5.79MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  71% 3.32G/4.66G [10:52<03:22, 6.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  43% 2.17G/5.00G [09:23<09:18, 5.07MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  73% 3.63G/4.97G [12:09<04:31, 4.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  90% 4.20G/4.66G [15:58<01:51, 4.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  42% 2.06G/4.97G [08:49<11:12, 4.32MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  53% 2.48G/4.66G [09:51<08:01, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  52% 2.42G/4.66G [09:40<07:33, 4.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  55% 2.55G/4.66G [09:51<06:12, 5.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  86% 4.29G/5.00G [15:05<02:31, 4.71MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  53% 2.48G/4.66G [09:41<06:02, 6.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  55% 2.55G/4.66G [09:52<06:16, 5.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  45% 2.24G/5.00G [09:32<08:31, 5.40MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  74% 3.69G/4.97G [12:15<03:44, 5.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  55% 2.55G/4.66G [09:47<05:16, 6.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  71% 3.32G/4.66G [11:10<03:22, 6.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  91% 4.26G/4.66G [16:11<01:35, 4.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  56% 2.62G/4.66G [10:03<05:58, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  46% 2.30G/5.00G [09:43<08:08, 5.51MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  76% 3.76G/4.97G [12:29<03:44, 5.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  42% 2.08G/4.97G [09:06<10:47, 4.45MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  55% 2.55G/4.66G [10:00<05:16, 6.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  86% 4.29G/5.00G [15:24<02:31, 4.71MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  73% 3.39G/4.66G [11:23<04:50, 4.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  47% 2.37G/5.00G [09:59<08:36, 5.09MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  77% 3.83G/4.97G [12:42<03:33, 5.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  44% 2.20G/4.97G [09:19<10:21, 4.45MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  58% 2.68G/4.66G [10:21<05:47, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  46% 2.26G/4.97G [09:23<07:25, 6.07MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  87% 4.35G/5.00G [15:37<03:01, 3.57MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  74% 3.46G/4.66G [11:38<04:30, 4.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  56% 2.62G/4.66G [10:17<07:29, 4.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  78% 3.89G/4.97G [12:52<03:20, 5.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  49% 2.44G/5.00G [10:10<08:22, 5.09MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  59% 2.75G/4.66G [10:32<06:08, 5.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  93% 4.33G/4.66G [16:43<01:33, 3.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  80% 3.96G/4.97G [13:00<02:45, 6.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  94% 4.40G/4.66G [16:49<01:03, 4.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  47% 2.33G/4.97G [09:37<07:37, 5.76MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  90% 4.49G/5.00G [15:52<01:47, 4.78MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  58% 2.68G/4.66G [10:28<06:47, 4.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  74% 3.46G/4.66G [11:50<04:30, 4.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  60% 2.82G/4.66G [10:43<05:38, 5.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  48% 2.40G/4.97G [09:46<07:02, 6.08MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  76% 3.53G/4.66G [11:57<04:36, 4.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  96% 4.46G/4.66G [16:59<00:43, 4.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  59% 2.75G/4.66G [10:37<05:57, 5.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  62% 2.89G/4.66G [10:50<04:54, 6.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  90% 4.49G/5.00G [16:04<01:47, 4.78MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  80% 3.96G/4.97G [13:12<02:45, 6.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  50% 2.51G/5.00G [10:32<08:58, 4.64MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  81% 4.03G/4.97G [13:14<02:45, 5.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  97% 4.53G/4.66G [17:04<00:23, 5.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  49% 2.42G/4.97G [09:52<07:33, 5.62MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  91% 4.55G/5.00G [16:07<01:33, 4.76MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  77% 3.59G/4.66G [12:08<03:56, 4.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  60% 2.82G/4.66G [10:48<05:29, 5.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  92% 4.62G/5.00G [16:13<01:08, 5.53MB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  51% 2.57G/5.00G [10:39<07:42, 5.25MB/s]\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  93% 4.66G/5.00G [16:13<00:52, 6.52MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  82% 4.09G/4.97G [13:21<02:18, 6.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  62% 2.89G/4.66G [11:01<04:54, 6.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  50% 2.48G/4.97G [10:02<06:58, 5.93MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  78% 3.63G/4.66G [12:13<03:24, 5.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  93% 4.67G/5.00G [16:17<00:51, 6.29MB/s]\u001b[A\n",
            "model-00018-of-00030.safetensors:  95% 4.73G/5.00G [16:22<00:37, 7.13MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  97% 4.53G/4.66G [17:21<00:23, 5.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  60% 2.82G/4.66G [11:00<05:29, 5.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  82% 4.09G/4.97G [13:32<02:18, 6.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  51% 2.57G/5.00G [10:50<07:42, 5.25MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  80% 3.73G/4.66G [12:25<02:41, 5.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  62% 2.89G/4.66G [11:04<05:51, 5.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors:  99% 4.60G/4.66G [17:27<00:14, 4.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  96% 4.80G/5.00G [16:32<00:27, 7.20MB/s]\u001b[A\n",
            "model-00018-of-00030.safetensors:  97% 4.87G/5.00G [16:32<00:12, 10.5MB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  52% 2.62G/5.00G [10:58<09:11, 4.32MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  81% 3.79G/4.66G [12:28<01:59, 7.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  63% 2.95G/4.66G [11:08<04:29, 6.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  63% 2.95G/4.66G [11:19<06:43, 4.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  84% 4.16G/4.97G [13:42<02:39, 5.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  51% 2.55G/4.97G [10:19<07:52, 5.11MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  83% 3.86G/4.66G [12:31<01:29, 8.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  65% 3.02G/4.66G [11:11<03:24, 8.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  66% 3.09G/4.66G [11:22<03:48, 6.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00017-of-00030.safetensors: 100% 4.66G/4.66G [17:33<00:00, 4.43MB/s]\n",
            "Fetching 30 files:  57% 17/30 [49:19<40:37, 187.53s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   0% 0.00/4.66G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  53% 2.62G/4.97G [10:22<05:53, 6.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  54% 2.68G/5.00G [11:03<07:12, 5.36MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  66% 3.09G/4.66G [11:13<02:30, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  67% 3.10G/4.66G [11:24<03:39, 7.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  85% 4.23G/4.97G [13:51<02:13, 5.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  56% 2.82G/5.00G [11:09<04:32, 7.99MB/s]\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors:  97% 4.87G/5.00G [16:44<00:12, 10.5MB/s]\u001b[A\n",
            "model-00018-of-00030.safetensors:  99% 4.93G/5.00G [16:44<00:08, 8.07MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  67% 3.12G/4.66G [11:20<02:56, 8.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00018-of-00030.safetensors: 100% 5.00G/5.00G [16:47<00:00, 4.96MB/s]\n",
            "Fetching 30 files:  60% 18/30 [49:30<29:00, 145.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  68% 3.17G/4.66G [11:34<03:31, 7.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  87% 4.30G/4.97G [13:55<01:39, 6.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   0% 0.00/4.66G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  54% 2.68G/4.97G [10:39<06:50, 5.56MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  83% 3.86G/4.66G [12:50<01:29, 8.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  56% 2.82G/5.00G [11:20<04:32, 7.99MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  68% 3.19G/4.66G [11:35<03:42, 6.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  69% 3.24G/4.66G [11:50<04:04, 5.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  89% 4.43G/4.97G [14:12<01:13, 7.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  54% 2.68G/4.97G [10:49<06:50, 5.56MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  55% 2.75G/4.97G [10:56<07:32, 4.90MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  68% 3.19G/4.66G [11:50<03:42, 6.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  89% 4.43G/4.97G [14:22<01:13, 7.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  71% 3.31G/4.66G [12:01<03:53, 5.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  91% 4.50G/4.97G [14:25<01:10, 6.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  84% 3.93G/4.66G [13:14<03:14, 3.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  92% 4.56G/4.97G [14:27<00:47, 8.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  70% 3.26G/4.66G [11:54<04:30, 5.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  93% 4.63G/4.97G [14:30<00:33, 9.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  58% 2.89G/4.97G [11:08<05:11, 6.69MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  58% 2.89G/5.00G [11:49<08:21, 4.21MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  87% 4.06G/4.66G [13:24<01:47, 5.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  95% 4.70G/4.97G [14:42<00:32, 8.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  71% 3.32G/4.66G [12:09<04:31, 4.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  59% 2.93G/4.97G [11:19<05:03, 6.69MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  58% 2.89G/5.00G [12:00<08:21, 4.21MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  60% 3.00G/4.97G [11:19<04:20, 7.55MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  59% 2.95G/5.00G [12:01<07:34, 4.51MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  87% 4.06G/4.66G [13:40<01:47, 5.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  71% 3.32G/4.66G [12:20<04:31, 4.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  95% 4.70G/4.97G [14:52<00:32, 8.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  73% 3.39G/4.66G [12:21<04:04, 5.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  72% 3.37G/4.66G [12:31<05:03, 4.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  89% 4.13G/4.66G [13:42<01:46, 5.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  62% 3.07G/4.97G [11:36<04:59, 6.33MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  63% 3.15G/5.00G [12:17<04:32, 6.78MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  90% 4.20G/4.66G [13:53<01:29, 5.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  96% 4.77G/4.97G [15:05<00:37, 5.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  74% 3.46G/4.66G [12:32<03:45, 5.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  63% 3.14G/4.97G [11:49<04:49, 6.33MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  63% 3.15G/5.00G [12:30<04:32, 6.78MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  74% 3.44G/4.66G [12:51<04:47, 4.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  97% 4.83G/4.97G [15:13<00:22, 6.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  64% 3.22G/5.00G [12:31<04:45, 6.23MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  91% 4.26G/4.66G [14:01<01:09, 5.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   1% 67.0M/4.66G [01:28<1:41:15, 757kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  75% 3.51G/4.66G [12:57<04:12, 4.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors:  99% 4.90G/4.97G [15:19<00:09, 6.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  76% 3.53G/4.66G [12:50<03:32, 5.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  93% 4.33G/4.66G [14:11<00:55, 6.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  64% 3.20G/4.97G [12:00<04:56, 5.95MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  77% 3.59G/4.66G [12:52<02:58, 5.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   0% 5.80M/4.66G [01:29<19:58:16, 64.8kB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  66% 3.29G/5.00G [12:43<04:44, 6.02MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  78% 3.66G/4.66G [12:57<02:25, 6.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  94% 4.40G/4.66G [14:17<00:38, 6.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  78% 3.64G/4.66G [13:08<02:52, 5.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   1% 31.8M/4.66G [01:33<2:52:32, 447kB/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00019-of-00030.safetensors: 100% 4.97G/4.97G [15:30<00:00, 5.33MB/s]\n",
            "Fetching 30 files:  63% 19/30 [51:05<24:15, 132.29s/it]\n",
            "\n",
            "model-00023-of-00030.safetensors:  69% 3.47G/5.00G [12:48<02:35, 9.81MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   0% 0.00/4.66G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   1% 67.0M/4.66G [01:47<1:41:15, 757kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   1% 67.0M/4.66G [01:49<2:15:11, 567kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  79% 3.71G/4.66G [13:17<02:36, 6.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  96% 4.46G/4.66G [14:27<00:29, 6.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  97% 4.53G/4.66G [14:28<00:14, 9.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   3% 134M/4.66G [01:55<48:50, 1.55MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  99% 4.60G/4.66G [14:29<00:05, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  80% 3.73G/4.66G [13:09<02:23, 6.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  64% 3.20G/4.97G [12:19<04:56, 5.95MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   1% 31.8M/4.66G [01:46<2:52:32, 447kB/s]\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  69% 3.47G/5.00G [13:00<02:35, 9.81MB/s]\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   2% 98.8M/4.66G [01:47<52:36, 1.45MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  66% 3.27G/4.97G [12:21<05:36, 5.05MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  71% 3.54G/5.00G [13:02<02:57, 8.26MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  82% 3.84G/4.66G [13:29<01:50, 7.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors:  99% 4.60G/4.66G [14:40<00:05, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   4% 201M/4.66G [02:07<48:07, 1.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  81% 3.79G/4.66G [13:20<02:13, 6.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  67% 3.34G/4.97G [12:31<05:08, 5.29MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  72% 3.60G/5.00G [13:12<03:00, 7.74MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   6% 268M/4.66G [02:09<21:16, 3.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  83% 3.86G/4.66G [13:28<01:59, 6.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   4% 166M/4.66G [02:06<51:49, 1.45MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  82% 3.84G/4.66G [13:41<01:50, 7.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  84% 3.91G/4.66G [13:42<01:52, 6.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   4% 166M/4.66G [02:08<36:59, 2.03MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00020-of-00030.safetensors: 100% 4.66G/4.66G [14:52<00:00, 5.22MB/s]\n",
            "Fetching 30 files:  67% 20/30 [51:39<17:40, 106.02s/it]\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  73% 3.67G/5.00G [13:26<03:15, 6.78MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   7% 335M/4.66G [02:23<19:00, 3.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  86% 3.99G/4.66G [13:37<01:18, 8.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   5% 233M/4.66G [02:14<23:23, 3.16MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  69% 3.40G/4.97G [12:47<05:11, 5.02MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:   9% 425M/4.66G [02:28<13:00, 5.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  87% 4.06G/4.66G [13:41<01:04, 9.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  85% 3.97G/4.66G [13:52<01:42, 6.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   6% 300M/4.66G [02:23<18:09, 4.00MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  70% 3.47G/4.97G [12:56<04:33, 5.46MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  75% 3.74G/5.00G [13:40<03:05, 6.78MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  76% 3.81G/5.00G [13:43<02:44, 7.28MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  12% 559M/4.66G [02:40<09:38, 7.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  88% 4.13G/4.66G [13:56<01:12, 7.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  90% 4.18G/4.66G [14:08<00:55, 8.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  71% 3.54G/4.97G [13:09<04:21, 5.46MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   6% 300M/4.66G [02:36<18:09, 4.00MB/s]\u001b[A\n",
            "model-00026-of-00030.safetensors:   8% 367M/4.66G [02:40<17:51, 4.01MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  73% 3.60G/4.97G [13:13<03:35, 6.33MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  77% 3.87G/5.00G [13:57<02:54, 6.45MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  12% 559M/4.66G [02:57<09:38, 7.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  90% 4.19G/4.66G [14:10<01:03, 7.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  90% 4.18G/4.66G [14:21<00:55, 8.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   1% 25.1M/4.66G [01:14<3:50:36, 335kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:   9% 429M/4.66G [02:51<16:06, 4.38MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  74% 3.67G/4.97G [13:29<03:24, 6.33MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  79% 3.94G/5.00G [14:10<02:44, 6.45MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  80% 4.01G/5.00G [14:12<02:15, 7.33MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  13% 626M/4.66G [03:09<14:13, 4.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  91% 4.25G/4.66G [14:37<01:12, 5.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   2% 92.7M/4.66G [01:27<58:12, 1.31MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  92% 4.31G/4.66G [14:38<00:49, 7.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  94% 4.38G/4.66G [14:38<00:30, 9.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   0% 574k/5.00G [00:55<133:15:05, 10.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  12% 563M/4.66G [03:06<15:35, 4.38MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  95% 4.45G/4.66G [14:42<00:20, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  81% 4.07G/5.00G [14:21<02:08, 7.19MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  97% 4.51G/4.66G [14:42<00:10, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  91% 4.26G/4.66G [14:35<01:19, 5.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  12% 563M/4.66G [03:12<13:13, 5.17MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  75% 3.74G/4.97G [13:45<03:53, 5.26MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  98% 4.58G/4.66G [14:47<00:06, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   0% 574k/5.00G [01:07<133:15:05, 10.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   2% 92.7M/4.66G [01:41<58:12, 1.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  13% 626M/4.66G [03:27<14:13, 4.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  93% 4.33G/4.66G [14:41<00:57, 5.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  77% 3.81G/4.97G [13:50<03:12, 6.04MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   1% 67.7M/5.00G [01:08<1:03:37, 1.29MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  83% 4.14G/5.00G [14:32<02:02, 6.99MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  94% 4.40G/4.66G [14:44<00:38, 7.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  14% 672M/4.66G [03:32<17:43, 3.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  96% 4.46G/4.66G [14:48<00:23, 8.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  14% 630M/4.66G [03:26<13:00, 5.17MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors:  99% 4.60G/4.66G [15:01<00:04, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  78% 3.87G/4.97G [14:01<03:00, 6.07MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  97% 4.53G/4.66G [14:58<00:17, 7.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  16% 739M/4.66G [03:45<16:14, 4.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   3% 160M/4.66G [01:59<46:06, 1.63MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  14% 672M/4.66G [03:35<13:14, 5.02MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  79% 3.94G/4.97G [14:08<02:32, 6.72MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   1% 67.7M/5.00G [01:27<1:03:37, 1.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  83% 4.14G/5.00G [14:50<02:02, 6.99MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  99% 4.60G/4.66G [15:01<00:07, 9.56MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  84% 4.21G/5.00G [14:51<02:22, 5.57MB/s]\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  16% 739M/4.66G [03:38<10:40, 6.13MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  82% 4.07G/4.97G [14:11<01:26, 10.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   3% 135M/5.00G [01:30<41:13, 1.97MB/s]   \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  19% 873M/4.66G [03:55<10:47, 5.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   5% 227M/4.66G [02:10<30:58, 2.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  16% 744M/4.66G [03:46<12:51, 5.08MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  83% 4.14G/4.97G [14:19<01:22, 9.98MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  86% 4.30G/5.00G [15:04<01:59, 5.87MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  22% 1.01G/4.66G [04:02<07:26, 8.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   6% 294M/4.66G [02:16<21:22, 3.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  85% 4.21G/4.97G [14:28<01:22, 9.22MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   4% 202M/5.00G [01:46<30:49, 2.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  87% 4.36G/5.00G [15:10<01:32, 6.86MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  23% 1.05G/4.66G [04:07<07:17, 8.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors:  99% 4.60G/4.66G [15:20<00:07, 9.56MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  16% 744M/4.66G [03:56<12:51, 5.08MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   8% 361M/4.66G [02:22<15:47, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00021-of-00030.safetensors: 100% 4.66G/4.66G [15:33<00:00, 4.99MB/s]\n",
            "Fetching 30 files:  70% 21/30 [53:30<16:05, 107.26s/it]\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  87% 4.30G/4.97G [14:32<01:00, 11.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  88% 4.38G/5.00G [15:19<01:52, 5.53MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  24% 1.12G/4.66G [04:16<07:24, 7.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   5% 269M/5.00G [01:57<30:23, 2.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:   9% 428M/4.66G [02:34<14:45, 4.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  17% 811M/4.66G [04:10<16:00, 4.01MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  88% 4.36G/4.97G [14:46<01:13, 8.23MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  89% 4.45G/5.00G [15:28<01:31, 6.05MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  25% 1.19G/4.66G [04:27<07:49, 7.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00022-of-00030.safetensors: 100% 4.66G/4.66G [15:40<00:00, 4.96MB/s]\n",
            "Fetching 30 files:  73% 22/30 [53:47<10:53, 81.72s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:   0% 0.00/2.10G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  20% 945M/4.66G [04:19<10:10, 6.09MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  89% 4.43G/4.97G [14:53<01:00, 8.82MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  92% 4.58G/5.00G [15:34<00:45, 9.22MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  28% 1.32G/4.66G [04:36<05:59, 9.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  11% 495M/4.66G [02:50<15:09, 4.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  93% 4.65G/5.00G [15:43<00:40, 8.65MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   7% 336M/5.00G [02:21<24:34, 3.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  13% 630M/4.66G [03:01<10:05, 6.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  89% 4.43G/4.97G [15:09<01:00, 8.82MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  28% 1.32G/4.66G [04:47<05:59, 9.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  22% 1.01G/4.66G [04:36<09:59, 6.09MB/s]\u001b[A\n",
            "model-00026-of-00030.safetensors:  23% 1.08G/4.66G [04:37<08:56, 6.68MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   8% 403M/5.00G [02:28<19:28, 3.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   0% 20.4k/4.97G [00:38<2580:15:56, 535B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  91% 4.50G/4.97G [15:11<01:13, 6.38MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  30% 1.39G/4.66G [04:49<06:49, 8.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  92% 4.56G/4.97G [15:11<00:45, 8.74MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  15% 697M/4.66G [03:05<08:29, 7.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  95% 4.73G/5.00G [15:54<00:32, 8.31MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:   9% 470M/5.00G [02:32<14:58, 5.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  93% 4.63G/4.97G [15:15<00:32, 10.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  96% 4.80G/5.00G [15:56<00:19, 10.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  16% 764M/4.66G [03:07<06:44, 9.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  95% 4.70G/4.97G [15:16<00:19, 13.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  97% 4.87G/5.00G [16:00<00:11, 11.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  96% 4.77G/4.97G [15:19<00:13, 14.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  25% 1.18G/4.66G [04:51<08:38, 6.73MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  12% 604M/5.00G [02:43<10:37, 6.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  97% 4.83G/4.97G [15:27<00:10, 12.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  19% 898M/4.66G [03:19<06:01, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  99% 4.90G/4.97G [15:28<00:04, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  27% 1.24G/4.66G [04:55<07:18, 7.81MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  32% 1.48G/4.66G [05:06<07:46, 6.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  99% 4.93G/5.00G [16:09<00:06, 9.90MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   0% 20.4k/4.97G [00:56<2580:15:56, 535B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  20% 940M/4.66G [03:21<05:33, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  28% 1.31G/4.66G [05:00<06:32, 8.55MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  35% 1.61G/4.66G [05:12<05:16, 9.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  16% 807M/5.00G [02:52<06:35, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors:  99% 4.90G/4.97G [15:39<00:04, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors:  99% 4.93G/5.00G [16:20<00:06, 9.90MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  22% 1.01G/4.66G [03:31<06:26, 9.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  30% 1.38G/4.66G [05:07<06:10, 8.87MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   1% 67.1M/4.97G [01:11<1:12:49, 1.12MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  36% 1.68G/4.66G [05:22<05:48, 8.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  19% 941M/5.00G [03:02<06:05, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  23% 1.07G/4.66G [03:37<06:02, 9.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  31% 1.44G/4.66G [05:13<05:36, 9.57MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00024-of-00030.safetensors: 100% 4.97G/4.97G [15:46<00:00, 5.25MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  37% 1.75G/4.66G [05:28<05:13, 9.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00023-of-00030.safetensors: 100% 5.00G/5.00G [16:31<00:00, 5.04MB/s]\n",
            "Fetching 30 files:  77% 23/30 [54:48<08:49, 75.66s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:   0% 693k/2.10G [01:00<51:17:14, 11.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  32% 1.51G/4.66G [05:18<05:12, 10.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  39% 1.81G/4.66G [05:34<04:53, 9.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  24% 1.14G/4.66G [03:51<05:55, 9.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  19% 941M/5.00G [03:17<06:05, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   4% 201M/4.97G [01:26<1:10:49, 1.12MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:   3% 67.7M/2.10G [01:12<27:13, 1.24MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  35% 1.64G/4.66G [05:33<05:14, 9.60MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  40% 1.88G/4.66G [05:45<05:33, 8.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  20% 1.01G/5.00G [03:25<08:59, 7.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  13% 269M/2.10G [01:17<05:20, 5.72MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  26% 1.21G/4.66G [03:59<07:28, 7.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  42% 1.95G/4.66G [05:47<04:15, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  19% 403M/2.10G [01:22<03:13, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  27% 1.27G/4.66G [04:04<06:29, 8.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  37% 1.71G/4.66G [05:40<05:05, 9.65MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  43% 2.01G/4.66G [05:54<04:24, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  23% 1.14G/5.00G [03:34<07:15, 8.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  22% 470M/2.10G [01:30<03:09, 8.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   4% 220M/4.97G [01:54<33:36, 2.35MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  45% 2.08G/4.66G [06:05<04:57, 8.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  30% 1.41G/4.66G [04:21<06:14, 8.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  24% 1.21G/5.00G [03:47<07:08, 8.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  37% 1.71G/4.66G [05:56<05:05, 9.65MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  26% 1.28G/5.00G [03:48<06:49, 9.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  32% 1.48G/4.66G [04:29<06:18, 8.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  38% 1.78G/4.66G [06:04<08:08, 5.91MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  46% 2.15G/4.66G [06:17<04:49, 8.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  22% 470M/2.10G [01:49<03:09, 8.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   6% 287M/4.97G [02:06<33:07, 2.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   7% 354M/4.97G [02:08<20:41, 3.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  27% 1.34G/5.00G [04:03<07:56, 7.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  35% 1.61G/4.66G [04:38<05:10, 9.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  41% 1.91G/4.66G [06:13<05:45, 7.97MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:   8% 421M/4.97G [02:16<17:29, 4.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  48% 2.22G/4.66G [06:28<05:48, 7.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  28% 1.41G/5.00G [04:08<07:08, 8.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  36% 1.68G/4.66G [04:43<04:51, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  13% 622M/4.97G [02:18<08:21, 8.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  49% 2.28G/4.66G [06:30<04:31, 8.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  50% 2.35G/4.66G [06:34<03:56, 9.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  14% 689M/4.97G [02:24<07:51, 9.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  41% 1.91G/4.66G [06:26<05:45, 7.97MB/s]\u001b[A\n",
            "model-00026-of-00030.safetensors:  42% 1.98G/4.66G [06:28<06:43, 6.66MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  26% 537M/2.10G [02:13<06:28, 4.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  30% 1.48G/5.00G [04:26<08:57, 6.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  36% 1.68G/4.66G [05:01<04:51, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  50% 2.35G/4.66G [06:47<03:56, 9.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  15% 756M/4.97G [02:36<07:43, 9.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  30% 1.48G/5.00G [04:37<08:57, 6.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  44% 2.05G/4.66G [06:46<06:33, 6.66MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  26% 537M/2.10G [02:29<06:28, 4.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  17% 823M/4.97G [03:10<13:23, 5.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  45% 2.11G/4.66G [07:11<09:15, 4.59MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  29% 604M/2.10G [02:54<08:37, 2.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  45% 2.11G/4.66G [07:26<09:15, 4.59MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  29% 604M/2.10G [03:09<08:37, 2.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  17% 823M/4.97G [03:26<13:23, 5.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  31% 1.54G/5.00G [05:20<18:17, 3.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  52% 2.42G/4.66G [07:49<14:05, 2.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  47% 2.18G/4.66G [07:40<10:57, 3.78MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  32% 671M/2.10G [03:29<09:21, 2.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  31% 1.54G/5.00G [05:37<18:17, 3.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  37% 1.74G/4.66G [06:17<18:18, 2.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  53% 2.48G/4.66G [08:07<13:40, 2.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  48% 2.25G/4.66G [07:56<10:39, 3.78MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  38% 805M/2.10G [03:39<08:29, 2.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  17% 842M/4.97G [03:57<24:01, 2.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  32% 1.61G/5.00G [05:53<20:39, 2.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  39% 1.81G/4.66G [06:31<17:53, 2.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  55% 2.55G/4.66G [08:18<10:42, 3.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  40% 1.88G/4.66G [06:32<12:43, 3.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  50% 2.32G/4.66G [08:13<10:05, 3.88MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  32% 1.61G/5.00G [06:07<20:39, 2.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  18% 909M/4.97G [04:16<23:38, 2.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  34% 1.68G/5.00G [06:08<17:55, 3.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  20% 976M/4.97G [04:21<18:45, 3.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  50% 2.32G/4.66G [08:22<11:26, 3.42MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  42% 873M/2.10G [04:05<05:39, 3.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  36% 1.81G/5.00G [06:14<10:44, 4.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  40% 1.88G/4.66G [06:51<12:43, 3.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  56% 2.62G/4.66G [08:37<10:22, 3.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  42% 1.95G/4.66G [06:54<12:59, 3.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  38% 1.88G/5.00G [06:25<09:58, 5.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  52% 2.42G/4.66G [08:36<10:57, 3.42MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  45% 940M/2.10G [04:19<05:21, 3.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  21% 1.03G/4.97G [04:36<18:31, 3.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  58% 2.68G/4.66G [08:48<09:05, 3.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  52% 2.42G/4.66G [08:41<09:35, 3.90MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  43% 2.01G/4.66G [07:11<12:40, 3.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  38% 1.88G/5.00G [06:37<09:58, 5.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  39% 1.95G/5.00G [06:38<09:54, 5.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  61% 2.86G/4.66G [08:59<05:33, 5.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  45% 2.08G/4.66G [07:19<10:39, 4.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  52% 2.42G/4.66G [08:56<09:35, 3.90MB/s]\u001b[A\n",
            "model-00026-of-00030.safetensors:  53% 2.48G/4.66G [09:00<09:29, 3.83MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  48% 1.01G/2.10G [04:49<05:22, 3.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  45% 2.08G/4.66G [07:31<10:39, 4.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  40% 2.01G/5.00G [06:57<09:41, 5.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  63% 2.93G/4.66G [09:17<05:21, 5.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  59% 2.75G/4.66G [09:12<04:10, 7.63MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  46% 2.15G/4.66G [07:37<10:36, 3.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  22% 1.09G/4.97G [05:12<21:32, 3.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  51% 1.07G/2.10G [04:55<04:22, 3.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  46% 2.15G/4.66G [07:51<10:36, 3.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  60% 2.82G/4.66G [09:26<04:01, 7.63MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  51% 1.07G/2.10G [05:09<04:22, 3.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  22% 1.09G/4.97G [05:26<21:32, 3.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  47% 2.21G/4.66G [08:05<11:56, 3.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  23% 1.16G/4.97G [05:41<22:25, 2.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  54% 1.14G/2.10G [05:25<04:44, 3.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  64% 3.00G/4.66G [09:54<07:04, 3.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  42% 2.08G/5.00G [07:34<13:57, 3.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  50% 2.35G/4.66G [08:08<07:07, 5.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  57% 1.21G/2.10G [05:28<03:30, 4.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  66% 3.06G/4.66G [09:56<05:42, 4.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  43% 2.15G/5.00G [07:36<10:53, 4.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  26% 1.29G/4.97G [05:49<14:53, 4.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  61% 1.28G/2.10G [05:38<02:57, 4.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  50% 2.35G/4.66G [08:21<07:07, 5.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  43% 2.15G/5.00G [07:47<10:53, 4.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  67% 3.13G/4.66G [10:07<05:28, 4.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  61% 1.28G/2.10G [05:49<02:57, 4.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  26% 1.29G/4.97G [06:06<14:53, 4.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  52% 2.42G/4.66G [08:50<10:29, 3.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  69% 3.20G/4.66G [10:42<06:19, 3.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  27% 1.36G/4.97G [06:36<20:23, 2.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  53% 2.48G/4.66G [09:01<10:10, 3.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  64% 1.34G/2.10G [06:28<04:26, 2.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  55% 2.55G/4.66G [09:09<08:02, 4.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  69% 3.20G/4.66G [10:57<06:19, 3.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  29% 1.43G/4.97G [06:46<20:00, 2.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  44% 2.21G/5.00G [08:41<19:12, 2.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  30% 1.49G/4.97G [06:52<14:50, 3.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  56% 2.62G/4.66G [09:21<07:46, 4.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  64% 1.34G/2.10G [06:39<04:26, 2.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  67% 1.41G/2.10G [06:41<03:33, 3.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  58% 2.68G/4.66G [09:28<06:27, 5.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  70% 3.26G/4.66G [11:14<07:03, 3.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  62% 2.89G/4.66G [11:03<10:06, 2.93MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  46% 2.28G/5.00G [08:57<18:44, 2.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  30% 1.49G/4.97G [07:06<14:50, 3.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  31% 1.56G/4.97G [07:10<14:40, 3.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  70% 1.48G/2.10G [06:58<03:04, 3.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  59% 2.75G/4.66G [09:40<06:10, 5.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  70% 3.26G/4.66G [11:27<07:03, 3.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  62% 2.89G/4.66G [11:16<10:06, 2.93MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  71% 3.30G/4.66G [11:32<07:22, 3.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  59% 2.75G/4.66G [09:51<06:10, 5.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  73% 1.54G/2.10G [07:09<02:44, 3.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  31% 1.56G/4.97G [07:26<14:40, 3.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  47% 2.35G/5.00G [09:18<15:44, 2.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  60% 2.82G/4.66G [09:58<06:25, 4.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  74% 1.57G/2.10G [07:16<02:21, 3.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  74% 3.44G/4.66G [11:45<04:42, 4.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  63% 2.95G/4.66G [11:34<10:18, 2.77MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  48% 2.42G/5.00G [09:24<12:45, 3.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  32% 1.61G/4.97G [07:40<18:02, 3.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  78% 1.63G/2.10G [07:23<01:42, 4.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  61% 2.83G/4.66G [10:05<07:00, 4.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  75% 3.50G/4.66G [11:51<03:51, 5.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  64% 2.99G/4.66G [11:40<09:34, 2.92MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  81% 1.70G/2.10G [07:29<01:13, 5.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  48% 2.42G/5.00G [09:37<12:45, 3.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  84% 1.77G/2.10G [07:37<00:55, 6.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  61% 2.83G/4.66G [10:21<07:00, 4.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  75% 3.50G/4.66G [12:07<03:51, 5.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  65% 3.02G/4.66G [11:56<09:21, 2.92MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  33% 1.66G/4.97G [07:56<17:45, 3.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  87% 1.83G/2.10G [07:44<00:39, 6.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  50% 2.48G/5.00G [09:52<13:34, 3.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  35% 1.73G/4.97G [08:03<14:47, 3.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  62% 2.90G/4.66G [10:37<09:03, 3.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  66% 3.09G/4.66G [12:13<08:45, 3.00MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  51% 2.55G/5.00G [10:04<11:39, 3.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  87% 1.83G/2.10G [07:59<00:39, 6.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  36% 1.80G/4.97G [08:16<14:28, 3.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  36% 1.80G/4.97G [08:19<14:00, 3.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  68% 3.16G/4.66G [12:20<07:01, 3.58MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  62% 2.90G/4.66G [10:51<09:03, 3.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  51% 2.55G/5.00G [10:17<11:39, 3.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  52% 2.62G/5.00G [10:23<11:18, 3.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  90% 1.90G/2.10G [08:16<00:48, 4.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  38% 1.86G/4.97G [08:33<13:00, 3.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  68% 3.16G/4.66G [12:36<07:01, 3.58MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  54% 2.68G/5.00G [10:37<10:59, 3.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  90% 1.90G/2.10G [08:29<00:48, 4.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  38% 1.86G/4.97G [08:46<13:00, 3.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  94% 1.97G/2.10G [08:41<00:37, 3.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  76% 3.54G/4.66G [13:09<09:09, 2.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  64% 2.96G/4.66G [11:23<11:51, 2.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  69% 3.22G/4.66G [13:04<09:00, 2.66MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  55% 2.75G/5.00G [10:55<09:54, 3.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  64% 2.97G/4.66G [11:41<14:57, 1.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  55% 2.75G/5.00G [11:07<09:54, 3.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  76% 3.54G/4.66G [13:27<09:09, 2.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  69% 3.22G/4.66G [13:16<09:00, 2.66MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  94% 1.97G/2.10G [08:59<00:37, 3.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  56% 2.82G/5.00G [11:13<09:41, 3.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  39% 1.93G/4.97G [09:22<19:15, 2.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  77% 3.61G/4.66G [13:34<08:04, 2.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  65% 3.03G/4.66G [11:51<14:22, 1.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  66% 3.10G/4.66G [11:53<07:34, 3.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  40% 2.00G/4.97G [09:35<16:12, 3.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  58% 2.89G/5.00G [11:27<09:23, 3.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  77% 3.61G/4.66G [13:47<08:04, 2.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  79% 3.67G/4.66G [13:50<06:29, 2.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  68% 3.17G/4.66G [12:04<06:17, 3.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  70% 3.26G/4.66G [13:45<11:47, 1.99MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  40% 2.00G/4.97G [09:46<16:12, 3.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  59% 2.95G/5.00G [11:37<07:57, 4.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  80% 3.74G/4.66G [14:02<05:06, 3.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  70% 3.26G/4.66G [13:51<12:42, 1.84MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  68% 3.17G/4.66G [12:21<06:17, 3.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  82% 3.81G/4.66G [14:14<04:06, 3.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  74% 3.46G/4.66G [14:04<04:39, 4.32MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  60% 3.02G/5.00G [11:57<07:41, 4.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  62% 3.08G/5.00G [12:00<06:42, 4.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  42% 2.06G/4.97G [10:10<18:24, 2.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  84% 3.92G/4.66G [14:21<02:25, 5.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  97% 2.03G/2.10G [09:59<00:36, 1.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  74% 3.46G/4.66G [14:16<04:39, 4.32MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  84% 3.93G/4.66G [14:33<03:02, 4.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  63% 3.15G/5.00G [12:17<06:28, 4.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors:  97% 2.03G/2.10G [10:09<00:36, 1.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  42% 2.08G/4.97G [10:26<18:18, 2.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  69% 3.23G/4.66G [12:52<09:11, 2.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  76% 3.53G/4.66G [14:28<04:58, 3.81MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  64% 3.22G/5.00G [12:21<05:39, 5.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  87% 4.06G/4.66G [14:43<01:38, 6.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  71% 3.30G/4.66G [12:57<06:42, 3.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  78% 3.62G/4.66G [14:33<03:17, 5.25MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  43% 2.15G/4.97G [10:33<16:15, 2.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  88% 4.10G/4.66G [14:45<01:20, 6.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  72% 3.37G/4.66G [13:00<04:45, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  45% 2.22G/4.97G [10:38<12:26, 3.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  66% 3.29G/5.00G [12:29<05:03, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  72% 3.37G/4.66G [13:11<04:45, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  88% 4.10G/4.66G [14:57<01:20, 6.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  78% 3.62G/4.66G [14:46<03:17, 5.25MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  66% 3.29G/5.00G [12:47<05:03, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  47% 2.35G/4.97G [10:56<11:50, 3.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00030-of-00030.safetensors: 100% 2.10G/2.10G [11:01<00:00, 3.18MB/s]\n",
            "\n",
            "model-00026-of-00030.safetensors:  79% 3.69G/4.66G [15:19<05:03, 3.20MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  49% 2.42G/4.97G [11:20<10:01, 4.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  89% 4.17G/4.66G [15:31<02:29, 3.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  67% 3.35G/5.00G [13:10<07:31, 3.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  79% 3.70G/4.66G [15:21<05:04, 3.18MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  68% 3.42G/5.00G [13:13<05:43, 4.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  74% 3.44G/4.66G [13:47<07:28, 2.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  80% 3.73G/4.66G [15:23<04:13, 3.70MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  91% 4.23G/4.66G [15:34<01:37, 4.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  91% 4.26G/4.66G [15:35<01:19, 5.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  69% 3.46G/5.00G [13:14<04:53, 5.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  93% 4.33G/4.66G [15:36<00:46, 7.20MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  51% 2.55G/4.97G [11:26<06:52, 5.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  70% 3.52G/5.00G [13:22<04:07, 5.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  75% 3.50G/4.66G [13:56<05:41, 3.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  81% 3.79G/4.66G [15:32<03:14, 4.47MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  72% 3.59G/5.00G [13:23<02:54, 8.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  77% 3.57G/4.66G [13:58<03:52, 4.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  93% 4.33G/4.66G [15:47<00:46, 7.20MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  51% 2.55G/4.97G [11:36<06:52, 5.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  94% 4.40G/4.66G [15:53<00:46, 5.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  73% 3.66G/5.00G [13:32<02:49, 7.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  83% 3.86G/4.66G [15:42<02:38, 5.07MB/s]\u001b[A\n",
            "model-00026-of-00030.safetensors:  84% 3.93G/4.66G [15:42<01:39, 7.42MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  76% 3.79G/5.00G [13:36<01:39, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  80% 3.71G/4.66G [14:11<02:29, 6.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  53% 2.62G/4.97G [11:52<08:23, 4.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  96% 4.46G/4.66G [16:03<00:33, 6.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  86% 3.99G/4.66G [15:53<01:33, 7.17MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  81% 3.78G/4.66G [14:17<02:06, 6.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  87% 4.06G/4.66G [15:55<01:05, 9.26MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  76% 3.79G/5.00G [13:47<01:39, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  82% 3.85G/4.66G [14:24<01:48, 7.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  97% 4.53G/4.66G [16:13<00:21, 6.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  54% 2.68G/4.97G [12:02<07:39, 4.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  89% 4.13G/4.66G [16:02<00:57, 9.27MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  84% 3.91G/4.66G [14:31<01:34, 7.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  55% 2.75G/4.97G [12:07<06:16, 5.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  77% 3.86G/5.00G [14:04<03:04, 6.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors:  99% 4.60G/4.66G [16:24<00:10, 6.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  89% 4.13G/4.66G [16:16<00:57, 9.27MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  79% 3.93G/5.00G [14:07<02:24, 7.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  57% 2.82G/4.97G [12:23<06:40, 5.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00025-of-00030.safetensors: 100% 4.66G/4.66G [16:34<00:00, 4.69MB/s]\n",
            "Fetching 30 files:  83% 25/30 [1:05:53<15:58, 191.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  84% 3.93G/4.66G [14:48<02:30, 4.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  86% 4.00G/4.66G [14:48<01:31, 7.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  90% 4.19G/4.66G [16:24<01:21, 5.76MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  58% 2.89G/4.97G [12:25<04:59, 6.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  91% 4.26G/4.66G [16:24<00:49, 8.13MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  87% 4.06G/4.66G [14:50<00:59, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  88% 4.13G/4.66G [14:51<00:38, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  93% 4.33G/4.66G [16:26<00:31, 10.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  59% 2.95G/4.97G [12:27<03:46, 8.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  61% 3.02G/4.97G [12:28<02:45, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  94% 4.40G/4.66G [16:34<00:26, 10.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  81% 4.06G/5.00G [14:24<02:03, 7.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  88% 4.13G/4.66G [15:01<00:38, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  90% 4.19G/4.66G [15:05<00:53, 8.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  83% 4.13G/5.00G [14:32<01:49, 7.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  62% 3.09G/4.97G [12:41<03:44, 8.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  96% 4.46G/4.66G [16:41<00:20, 9.62MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  84% 4.19G/5.00G [14:32<01:17, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  97% 4.53G/4.66G [16:42<00:10, 13.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  64% 3.15G/4.97G [12:47<03:20, 9.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  65% 3.22G/4.97G [12:47<02:17, 12.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  66% 3.29G/4.97G [12:51<02:02, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  85% 4.26G/5.00G [14:42<01:20, 9.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  91% 4.26G/4.66G [15:17<00:54, 7.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  87% 4.33G/5.00G [14:46<01:03, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  97% 4.53G/4.66G [16:56<00:10, 13.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  88% 4.40G/5.00G [14:48<00:47, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors:  99% 4.60G/4.66G [16:58<00:08, 8.07MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  89% 4.46G/5.00G [14:54<00:44, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  93% 4.33G/4.66G [15:29<00:49, 6.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  66% 3.29G/4.97G [13:06<02:02, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00026-of-00030.safetensors: 100% 4.66G/4.66G [17:08<00:00, 4.54MB/s]\n",
            "Fetching 30 files:  87% 26/30 [1:06:39<10:24, 156.02s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  94% 4.40G/4.66G [15:33<00:32, 8.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  68% 3.35G/4.97G [13:12<03:49, 7.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  69% 3.42G/4.97G [13:16<03:02, 8.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  96% 4.46G/4.66G [15:41<00:24, 8.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  70% 3.47G/4.97G [13:16<02:18, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  89% 4.46G/5.00G [15:07<00:44, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  70% 3.49G/4.97G [13:22<02:48, 8.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  91% 4.53G/5.00G [15:13<01:04, 7.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  92% 4.60G/5.00G [15:16<00:45, 8.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  96% 4.46G/4.66G [15:51<00:24, 8.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  72% 3.56G/4.97G [13:28<02:30, 9.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  97% 4.53G/4.66G [15:53<00:18, 7.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors:  99% 4.60G/4.66G [15:53<00:06, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  73% 3.63G/4.97G [13:29<01:38, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  74% 3.69G/4.97G [13:31<01:17, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00027-of-00030.safetensors: 100% 4.66G/4.66G [15:56<00:00, 4.87MB/s]\n",
            "Fetching 30 files:  90% 27/30 [1:07:02<06:05, 121.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  76% 3.76G/4.97G [13:32<00:53, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  93% 4.66G/5.00G [15:23<00:36, 9.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  77% 3.83G/4.97G [13:32<00:37, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  78% 3.89G/4.97G [13:33<00:25, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  80% 3.96G/4.97G [13:39<00:43, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  81% 4.03G/4.97G [13:40<00:34, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  82% 4.09G/4.97G [13:43<00:33, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  95% 4.73G/5.00G [15:33<00:32, 8.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  96% 4.80G/5.00G [15:37<00:20, 9.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  84% 4.16G/4.97G [13:47<00:36, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  97% 4.87G/5.00G [15:38<00:10, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  85% 4.23G/4.97G [13:48<00:25, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  87% 4.30G/4.97G [13:48<00:16, 39.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  88% 4.36G/4.97G [13:48<00:11, 53.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  89% 4.43G/4.97G [13:48<00:07, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors:  99% 4.93G/5.00G [15:39<00:03, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00028-of-00030.safetensors: 100% 5.00G/5.00G [15:40<00:00, 5.32MB/s]\n",
            "Fetching 30 files:  93% 28/30 [1:07:20<03:07, 93.68s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  91% 4.50G/4.97G [13:49<00:06, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  92% 4.56G/4.97G [13:49<00:04, 92.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  93% 4.63G/4.97G [13:53<00:07, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  95% 4.70G/4.97G [13:53<00:04, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  96% 4.77G/4.97G [13:53<00:02, 78.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  97% 4.83G/4.97G [13:54<00:01, 99.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors:  99% 4.90G/4.97G [13:54<00:00, 119MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00029-of-00030.safetensors: 100% 4.97G/4.97G [13:54<00:00, 5.95MB/s]\n",
            "Fetching 30 files: 100% 30/30 [1:07:25<00:00, 134.84s/it]\n",
            "Loading checkpoint shards: 100% 30/30 [01:13<00:00,  2.45s/it]\n",
            "generation_config.json: 100% 189/189 [00:00<00:00, 1.51MB/s]\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Loaded llama3 (meta-llama/Llama-3.3-70B-Instruct) model with ~70,553,706,496 parameters (dtype=torch.float16).\n",
            "=== Compressing ===\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/EE274-LLM-Compressor/scl/Project/llm_compressor.py\", line 493, in <module>\n",
            "    main_demo()\n",
            "  File \"/content/EE274-LLM-Compressor/scl/Project/llm_compressor.py\", line 419, in main_demo\n",
            "    encoded_bitarray = compress_text_to_bitarray(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/EE274-LLM-Compressor/scl/Project/llm_compressor.py\", line 332, in compress_text_to_bitarray\n",
            "    encoded_chunk = encoder.encode_block(data_block)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/EE274-LLM-Compressor/scl/compressors/arithmetic_coding.py\", line 118, in encode_block\n",
            "    self.freq_model.update_model(s)\n",
            "  File \"/content/EE274-LLM-Compressor/scl/Project/llm_compressor.py\", line 209, in update_model\n",
            "    outputs = self.model(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n",
            "    output = module._old_forward(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 918, in wrapper\n",
            "    output = func(self, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 459, in forward\n",
            "    outputs: BaseModelOutputWithPast = self.model(\n",
            "                                       ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 1072, in wrapper\n",
            "    outputs = func(self, *args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 395, in forward\n",
            "    hidden_states = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 94, in __call__\n",
            "    return super().__call__(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n",
            "    output = module._old_forward(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 309, in forward\n",
            "    hidden_states = self.mlp(hidden_states)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n",
            "    output = module._old_forward(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 155, in forward\n",
            "    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
            "                                           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\", line 170, in new_forward\n",
            "    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\", line 341, in pre_forward\n",
            "    value = self.weights_map[name]\n",
            "            ~~~~~~~~~~~~~~~~^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\", line 118, in __getitem__\n",
            "    return self.dataset[f\"{self.prefix}{key}\"]\n",
            "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/offload.py\", line 171, in __getitem__\n",
            "    tensor = f.get_tensor(weight_info.get(\"weight_name\", key))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python llm_compressor.py --model llama3 --hf-token <insert your own token>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}